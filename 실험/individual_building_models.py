# ðŸ“Š ê°œë³„ ê±´ë¬¼ ëª¨ë¸ë§ (Individual Building Models)
# Dacon 1ìœ„ ì†”ë£¨ì…˜ì˜ í•µì‹¬ ì „ëžµ êµ¬í˜„

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.preprocessing import LabelEncoder
import pickle
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

print("ðŸš€ ê°œë³„ ê±´ë¬¼ ëª¨ë¸ë§ ì‹œìž‘!")
print("=" * 50)

# 1. ë°ì´í„° ë¡œë“œ
print("ðŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
train_df = pd.read_csv('data/train.csv')
test_df = pd.read_csv('data/test.csv')
building_info = pd.read_csv('data/building_info.csv')
sample_submission = pd.read_csv('data/sample_submission.csv')

print(f"âœ… Train ë°ì´í„°: {train_df.shape}")
print(f"âœ… Test ë°ì´í„°: {test_df.shape}")
print(f"âœ… Building info: {building_info.shape}")
print(f"âœ… ì´ ê±´ë¬¼ ìˆ˜: {len(building_info)}")

# 2. Feature Engineering í•¨ìˆ˜
def create_features(df, building_info):
    """
    Feature Engineering í•¨ìˆ˜ - ì‹œê°„, ê¸°ìƒ, ê±´ë¬¼ ê´€ë ¨ í”¼ì²˜ ìƒì„±
    """
    df = df.copy()
    
    # ê±´ë¬¼ ì •ë³´ ë³‘í•©
    building_info_processed = building_info.copy()
    
    # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° (ê²°ì¸¡ì¹˜ê°€ ë§Žì€ ì»¬ëŸ¼ë“¤)
    drop_columns = ['íƒœì–‘ê´‘ìš©ëŸ‰(kW)', 'ESSì €ìž¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)']
    for col in drop_columns:
        if col in building_info_processed.columns:
            building_info_processed = building_info_processed.drop(col, axis=1)
    
    # ê±´ë¬¼ ì •ë³´ ë³‘í•©
    df = df.merge(building_info_processed, on='ê±´ë¬¼ë²ˆí˜¸', how='left')
    
    # ì›ë³¸ ë°ì´í„°ì—ì„œ ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
    drop_original_columns = ['ì¼ì¡°(hr)', 'ì¼ì‚¬(MJ/m2)']
    for col in drop_original_columns:
        if col in df.columns:
            df = df.drop(col, axis=1)
    
    # ë‚ ì§œ/ì‹œê°„ ë³€í™˜
    df['ì¼ì‹œ'] = pd.to_datetime(df['ì¼ì‹œ'], format='%Y%m%d %H')
    
    # ì‹œê°„ ê´€ë ¨ í”¼ì²˜
    df['ì—°ë„'] = df['ì¼ì‹œ'].dt.year
    df['ì›”'] = df['ì¼ì‹œ'].dt.month
    df['ì¼'] = df['ì¼ì‹œ'].dt.day
    df['ì‹œê°„'] = df['ì¼ì‹œ'].dt.hour
    df['ìš”ì¼'] = df['ì¼ì‹œ'].dt.dayofweek
    df['ì£¼ë§ì—¬ë¶€'] = (df['ìš”ì¼'] >= 5).astype(int)
    
    # ê³„ì ˆ í”¼ì²˜
    df['ê³„ì ˆ'] = df['ì›”'].apply(lambda x: 0 if x in [12, 1, 2] else 
                              1 if x in [3, 4, 5] else 
                              2 if x in [6, 7, 8] else 3)
    
    # ì‹œê°„ëŒ€ êµ¬ë¶„
    df['ì‹œê°„ëŒ€'] = df['ì‹œê°„'].apply(lambda x: 0 if 6 <= x < 12 else 
                                1 if 12 <= x < 18 else 
                                2 if 18 <= x < 24 else 3)
    
    # ì˜¨ë„ ê´€ë ¨ í”¼ì²˜
    df['ì˜¨ë„_ì œê³±'] = df['ê¸°ì˜¨(Â°C)'] ** 2
    
    # CDH (Cooling Degree Hours) - ëƒ‰ë°©ë„ì‹œ
    df['CDH'] = np.maximum(df['ê¸°ì˜¨(Â°C)'] - 26, 0)
    
    # THI (Temperature Humidity Index) - ì˜¨ìŠµë„ì§€ìˆ˜
    df['THI'] = 9/5 * df['ê¸°ì˜¨(Â°C)'] - 0.55 * (1 - df['ìŠµë„(%)'] / 100) * (9/5 * df['ê¸°ì˜¨(Â°C)'] - 26) + 32
    
    # ê¸°ìƒ ìƒí˜¸ìž‘ìš©
    df['ìŠµë„_ì˜¨ë„'] = df['ìŠµë„(%)'] * df['ê¸°ì˜¨(Â°C)']
    df['ë°”ëžŒì„¸ê¸°'] = df['í’ì†(m/s)'] * df['ê¸°ì˜¨(Â°C)']
    
    # ê±´ë¬¼ ê´€ë ¨ í”¼ì²˜
    df['ëƒ‰ë°©ë©´ì _ë¹„ìœ¨'] = df['ëƒ‰ë°©ë©´ì (m2)'] / (df['ì—°ë©´ì (m2)'] + 1)
    
    return df

print("\nðŸ”§ Feature Engineering ì ìš© ì¤‘...")
train_processed = create_features(train_df, building_info)
test_processed = create_features(test_df, building_info)

print(f"âœ… ì²˜ë¦¬ëœ train ë°ì´í„°: {train_processed.shape}")
print(f"âœ… ì²˜ë¦¬ëœ test ë°ì´í„°: {test_processed.shape}")

# 3. í”¼ì²˜ ì¤€ë¹„
exclude_columns = ['num_date_time', 'ì¼ì‹œ', 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']
feature_columns = [col for col in train_processed.columns if col not in exclude_columns]

print(f"âœ… ì‚¬ìš©í•  í”¼ì²˜ ìˆ˜: {len(feature_columns)}")
print(f"í”¼ì²˜ ëª©ë¡: {feature_columns[:10]}...")  # ì²« 10ê°œë§Œ ì¶œë ¥

# ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ ì¸ì½”ë”©
categorical_features = ['ê±´ë¬¼ìœ í˜•']
label_encoders = {}

for cat_col in categorical_features:
    if cat_col in train_processed.columns:
        le = LabelEncoder()
        # ì „ì²´ ë°ì´í„°(train + test)ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ì½”ë” í•™ìŠµ
        all_categories = pd.concat([train_processed[cat_col], test_processed[cat_col]]).astype(str).unique()
        le.fit(all_categories)
        
        train_processed[cat_col] = le.transform(train_processed[cat_col].astype(str))
        test_processed[cat_col] = le.transform(test_processed[cat_col].astype(str))
        label_encoders[cat_col] = le

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
# trainê³¼ testì—ì„œ ê³µí†µìœ¼ë¡œ ì¡´ìž¬í•˜ëŠ” numeric ì»¬ëŸ¼ë§Œ ì²˜ë¦¬
train_numeric_columns = train_processed.select_dtypes(include=[np.number]).columns
test_numeric_columns = test_processed.select_dtypes(include=[np.number]).columns
common_numeric_columns = list(set(train_numeric_columns) & set(test_numeric_columns))

train_processed[train_numeric_columns] = train_processed[train_numeric_columns].fillna(train_processed[train_numeric_columns].mean())
test_processed[test_numeric_columns] = test_processed[test_numeric_columns].fillna(test_processed[test_numeric_columns].mean())

print("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")

# 4. ê°œë³„ ê±´ë¬¼ ëª¨ë¸ í›ˆë ¨
print("\nðŸ¢ ê°œë³„ ê±´ë¬¼ ëª¨ë¸ í›ˆë ¨ ì‹œìž‘...")
print("=" * 50)

# ëª¨ë¸ ì €ìž¥ìš© ë”•ì…”ë„ˆë¦¬
building_models = {}
building_predictions = {}
building_scores = {}

# ê° ê±´ë¬¼ë³„ë¡œ ëª¨ë¸ í›ˆë ¨
unique_buildings = sorted(train_processed['ê±´ë¬¼ë²ˆí˜¸'].unique())
total_buildings = len(unique_buildings)

for idx, building_num in enumerate(unique_buildings, 1):
    print(f"\nðŸ¢ ê±´ë¬¼ {building_num} ëª¨ë¸ í›ˆë ¨ ì¤‘... ({idx}/{total_buildings})")
    
    # í•´ë‹¹ ê±´ë¬¼ ë°ì´í„° í•„í„°ë§
    train_building = train_processed[train_processed['ê±´ë¬¼ë²ˆí˜¸'] == building_num].copy()
    test_building = test_processed[test_processed['ê±´ë¬¼ë²ˆí˜¸'] == building_num].copy()
    
    print(f"   ðŸ“Š í›ˆë ¨ ë°ì´í„°: {len(train_building)}ê°œ")
    print(f"   ðŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_building)}ê°œ")
    
    # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
    X_building = train_building[feature_columns].copy()
    y_building = train_building['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'].copy()
    X_test_building = test_building[feature_columns].copy()
    
    # í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¶„í• 
    X_train, X_val, y_train, y_val = train_test_split(
        X_building, y_building, test_size=0.2, random_state=42
    )
    
    # XGBoost ëª¨ë¸ ì„¤ì •
    xgb_params = {
        'objective': 'reg:squarederror',
        'eval_metric': 'rmse',
        'max_depth': 6,
        'learning_rate': 0.1,
        'n_estimators': 200,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'random_state': 42,
        'n_jobs': -1,
        'verbosity': 0
    }
    
    # ëª¨ë¸ í›ˆë ¨
    model = xgb.XGBRegressor(**xgb_params)
    
    # ëª¨ë¸ í›ˆë ¨ (ë‹¨ìˆœí™”)
    model.fit(X_train, y_train)
    
    # ê²€ì¦ ì„±ëŠ¥ í‰ê°€
    val_pred = model.predict(X_val)
    val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))
    val_mae = mean_absolute_error(y_val, val_pred)
    
    print(f"   ðŸ“ˆ ê²€ì¦ RMSE: {val_rmse:.2f} kWh")
    print(f"   ðŸ“ˆ ê²€ì¦ MAE: {val_mae:.2f} kWh")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
    test_pred = model.predict(X_test_building)
    
    # ìŒìˆ˜ê°’ ì²˜ë¦¬ (ì „ë ¥ì†Œë¹„ëŸ‰ì€ 0 ì´ìƒì´ì–´ì•¼ í•¨)
    test_pred = np.maximum(test_pred, 0)
    
    # ê²°ê³¼ ì €ìž¥
    building_models[building_num] = model
    building_predictions[building_num] = test_pred
    building_scores[building_num] = {'rmse': val_rmse, 'mae': val_mae}

print(f"\nâœ… ì´ {len(building_models)}ê°œ ê±´ë¬¼ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")

# 5. ì˜ˆì¸¡ ê²°ê³¼ ì¡°í•© ë° ì œì¶œ íŒŒì¼ ìƒì„±
print("\nðŸ“ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆœì„œëŒ€ë¡œ ì˜ˆì¸¡ê°’ ë°°ì—´
final_predictions = []

for idx, row in test_processed.iterrows():
    building_num = row['ê±´ë¬¼ë²ˆí˜¸']
    # í•´ë‹¹ ê±´ë¬¼ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œì˜ ìˆœì„œ ì°¾ê¸°
    building_test_data = test_processed[test_processed['ê±´ë¬¼ë²ˆí˜¸'] == building_num]
    building_idx = list(building_test_data.index).index(idx)
    
    # í•´ë‹¹ ê±´ë¬¼ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ê°€ì ¸ì˜¤ê¸°
    prediction = building_predictions[building_num][building_idx]
    final_predictions.append(prediction)

# ì œì¶œ íŒŒì¼ ìƒì„±
submission = sample_submission.copy()
submission['answer'] = final_predictions

# ê²°ê³¼ ì €ìž¥
submission.to_csv('individual_building_submission.csv', index=False)

print("âœ… ì œì¶œ íŒŒì¼ ì €ìž¥: individual_building_submission.csv")

# 6. ê²°ê³¼ ë¶„ì„
print("\nðŸ“Š ê²°ê³¼ ë¶„ì„")
print("=" * 50)

# ì „ì²´ ì„±ëŠ¥ í†µê³„
all_rmse = [score['rmse'] for score in building_scores.values()]
all_mae = [score['mae'] for score in building_scores.values()]

print(f"ðŸ† ì „ì²´ ê±´ë¬¼ í‰ê·  ì„±ëŠ¥:")
print(f"   ðŸ“ˆ í‰ê·  RMSE: {np.mean(all_rmse):.2f} Â± {np.std(all_rmse):.2f} kWh")
print(f"   ðŸ“ˆ í‰ê·  MAE: {np.mean(all_mae):.2f} Â± {np.std(all_mae):.2f} kWh")
print(f"   ðŸ“ˆ ìµœê³  RMSE: {np.min(all_rmse):.2f} kWh (ê±´ë¬¼ {min(building_scores.keys(), key=lambda x: building_scores[x]['rmse'])})")
print(f"   ðŸ“ˆ ìµœì € RMSE: {np.max(all_rmse):.2f} kWh (ê±´ë¬¼ {max(building_scores.keys(), key=lambda x: building_scores[x]['rmse'])})")

# ì˜ˆì¸¡ ê²°ê³¼ í†µê³„
print(f"\nðŸŽ¯ ì˜ˆì¸¡ ê²°ê³¼ í†µê³„:")
print(f"   ðŸ“Š ì˜ˆì¸¡ í‰ê· : {np.mean(final_predictions):.2f} kWh")
print(f"   ðŸ“Š ì˜ˆì¸¡ ì¤‘ì•™ê°’: {np.median(final_predictions):.2f} kWh")
print(f"   ðŸ“Š ì˜ˆì¸¡ ë²”ìœ„: {np.min(final_predictions):.2f} ~ {np.max(final_predictions):.2f} kWh")
print(f"   ðŸ“Š ì˜ˆì¸¡ í‘œì¤€íŽ¸ì°¨: {np.std(final_predictions):.2f} kWh")

# ê±´ë¬¼ë³„ ì„±ëŠ¥ì´ ì¢‹ì€/ë‚˜ìœ ìƒìœ„ 5ê°œ
print(f"\nðŸ† ì„±ëŠ¥ì´ ê°€ìž¥ ì¢‹ì€ ê±´ë¬¼ TOP 5:")
best_buildings = sorted(building_scores.items(), key=lambda x: x[1]['rmse'])[:5]
for building, score in best_buildings:
    print(f"   ê±´ë¬¼ {building}: RMSE {score['rmse']:.2f} kWh")

print(f"\nâš ï¸  ì„±ëŠ¥ ê°œì„ ì´ í•„ìš”í•œ ê±´ë¬¼ TOP 5:")
worst_buildings = sorted(building_scores.items(), key=lambda x: x[1]['rmse'], reverse=True)[:5]
for building, score in worst_buildings:
    print(f"   ê±´ë¬¼ {building}: RMSE {score['rmse']:.2f} kWh")

# ëª¨ë¸ ì €ìž¥
print(f"\nðŸ’¾ ëª¨ë¸ ì €ìž¥ ì¤‘...")
os.makedirs('individual_models', exist_ok=True)

# ê° ê±´ë¬¼ ëª¨ë¸ ì €ìž¥
for building_num, model in building_models.items():
    model_path = f'individual_models/building_{building_num}_model.pkl'
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)

# ì „ì²´ ê²°ê³¼ ì €ìž¥
results_summary = {
    'building_scores': building_scores,
    'feature_columns': feature_columns,
    'label_encoders': label_encoders,
    'summary_stats': {
        'mean_rmse': np.mean(all_rmse),
        'std_rmse': np.std(all_rmse),
        'mean_mae': np.mean(all_mae),
        'std_mae': np.std(all_mae)
    }
}

with open('individual_models/results_summary.pkl', 'wb') as f:
    pickle.dump(results_summary, f)

print("âœ… ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: individual_models/ í´ë”")

print(f"\nðŸŽ‰ ê°œë³„ ê±´ë¬¼ ëª¨ë¸ë§ ì™„ë£Œ!")
print("=" * 50)
print("ðŸ“ ìƒì„±ëœ íŒŒì¼:")
print("   âœ… individual_building_submission.csv - ì œì¶œ íŒŒì¼")
print("   âœ… individual_models/ - í›ˆë ¨ëœ ëª¨ë¸ë“¤")
print("   âœ… individual_models/results_summary.pkl - ê²°ê³¼ ìš”ì•½")
print(f"\nðŸ’¡ ë‹¤ìŒ ë‹¨ê³„: ì´ ê²°ê³¼ë¥¼ ë‹¤ë¥¸ ëª¨ë¸(ì „ì²´ ëª¨ë¸, ê±´ë¬¼ìœ í˜•ë³„ ëª¨ë¸)ê³¼ ì•™ìƒë¸”í•´ë³´ì„¸ìš”!") 