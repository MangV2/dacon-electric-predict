{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 📊 전력 사용량 예측 앙상블 모델\n",
        "\n",
        "이 노트북에서는 **건물별 모델**과 **건물 타입별 모델**을 각각 구현하고 앙상블하여 최종 예측을 수행합니다.\n",
        "\n",
        "## 🔧 주요 전략\n",
        "1. **전처리 방식 적용**: CDH, THI, WCT, 주기성 피처 등\n",
        "2. **건물별 개별 모델**: 100개 건물 각각에 대한 전용 모델\n",
        "3. **건물 타입별 모델**: 10개 건물 유형별 모델\n",
        "4. **가중 앙상블**: 개별 건물 모델 70% + 건물 타입별 모델 30%\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. 라이브러리 및 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost 버전: 1.6.1\n",
            "🚀 전력 사용량 예측 앙상블 모델 시작!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import sklearn\n",
        "import xgboost\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "import random as rn\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# 시드 설정\n",
        "RANDOM_SEED = 2025\n",
        "np.random.seed(RANDOM_SEED)\n",
        "rn.seed(RANDOM_SEED)\n",
        "\n",
        "# XGBoost 버전 확인\n",
        "print(f\"XGBoost 버전: {xgboost.__version__}\")\n",
        "\n",
        "print(\"🚀 전력 사용량 예측 앙상블 모델 시작!\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. 평가 함수 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 평가 함수 정의 완료\n"
          ]
        }
      ],
      "source": [
        "def smape(gt, preds):\n",
        "    \"\"\"SMAPE (Symmetric Mean Absolute Percentage Error) 계산\"\"\"\n",
        "    gt = np.array(gt)\n",
        "    preds = np.array(preds)\n",
        "    v = 2 * abs(preds - gt) / (abs(preds) + abs(gt))\n",
        "    score = np.mean(v) * 100\n",
        "    return score\n",
        "    \n",
        "def weighted_mse(alpha=1):\n",
        "    \"\"\"가중 MSE 손실 함수 (Under-prediction에 더 큰 페널티)\"\"\"\n",
        "    def weighted_mse_fixed(label, pred):\n",
        "        residual = (label - pred).astype(\"float\")\n",
        "        grad = np.where(residual > 0, -2 * alpha * residual, -2 * residual)\n",
        "        hess = np.where(residual > 0, 2 * alpha, 2.0)\n",
        "        return grad, hess\n",
        "    return weighted_mse_fixed\n",
        "\n",
        "def custom_smape(preds, dtrain):\n",
        "    \"\"\"XGBoost용 SMAPE 평가 함수\"\"\"\n",
        "    labels = dtrain.get_label()\n",
        "    return 'custom_smape', np.mean(2 * abs(preds - labels) / (abs(preds) + abs(labels))) * 100\n",
        "\n",
        "print(\"✅ 평가 함수 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. 데이터 로드 및 기본 전처리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 데이터 로드 중...\n",
            "✅ Train 데이터: (204000, 10)\n",
            "✅ Test 데이터: (16800, 7)\n",
            "✅ Building info: (100, 7)\n",
            "✅ 기본 전처리 완료\n"
          ]
        }
      ],
      "source": [
        "# 데이터 로드\n",
        "print(\"📊 데이터 로드 중...\")\n",
        "train = pd.read_csv('data/train.csv')\n",
        "test = pd.read_csv('data/test.csv')\n",
        "building_info = pd.read_csv('data/building_info.csv')\n",
        "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
        "\n",
        "print(f\"✅ Train 데이터: {train.shape}\")\n",
        "print(f\"✅ Test 데이터: {test.shape}\")\n",
        "print(f\"✅ Building info: {building_info.shape}\")\n",
        "\n",
        "# 컬럼명 영어로 변경 (작년 수상자 방식)\n",
        "train = train.rename(columns={\n",
        "    '건물번호': 'building_number',\n",
        "    '일시': 'date_time',\n",
        "    '기온(°C)': 'temperature',\n",
        "    '강수량(mm)': 'rainfall',\n",
        "    '풍속(m/s)': 'windspeed',\n",
        "    '습도(%)': 'humidity',\n",
        "    '일조(hr)': 'sunshine',\n",
        "    '일사(MJ/m2)': 'solar_radiation',\n",
        "    '전력소비량(kWh)': 'power_consumption'\n",
        "})\n",
        "train.drop('num_date_time', axis=1, inplace=True)\n",
        "\n",
        "test = test.rename(columns={\n",
        "    '건물번호': 'building_number',\n",
        "    '일시': 'date_time',\n",
        "    '기온(°C)': 'temperature',\n",
        "    '강수량(mm)': 'rainfall',\n",
        "    '풍속(m/s)': 'windspeed',\n",
        "    '습도(%)': 'humidity',\n",
        "    '일조(hr)': 'sunshine',\n",
        "    '일사(MJ/m2)': 'solar_radiation'\n",
        "})\n",
        "test.drop('num_date_time', axis=1, inplace=True)\n",
        "\n",
        "building_info = building_info.rename(columns={\n",
        "    '건물번호': 'building_number',\n",
        "    '건물유형': 'building_type',\n",
        "    '연면적(m2)': 'total_area',\n",
        "    '냉방면적(m2)': 'cooling_area',\n",
        "    '태양광용량(kW)': 'solar_power_capacity',\n",
        "    'ESS저장용량(kWh)': 'ess_capacity',\n",
        "    'PCS용량(kW)': 'pcs_capacity'\n",
        "})\n",
        "\n",
        "# 건물 유형 영어로 번역\n",
        "translation_dict = {\n",
        "    '건물기타': 'Other Buildings',\n",
        "    '공공': 'Public',\n",
        "    '학교': 'University',\n",
        "    '백화점': 'Department Store',\n",
        "    '병원': 'Hospital',\n",
        "    '상용': 'Commercial',\n",
        "    '아파트': 'Apartment',\n",
        "    '연구소': 'Research Institute',\n",
        "    'IDC(전화국)': 'IDC',\n",
        "    '호텔': 'Hotel'\n",
        "}\n",
        "building_info['building_type'] = building_info['building_type'].replace(translation_dict)\n",
        "\n",
        "# 태양광/ESS 설비 유무 피처 생성\n",
        "building_info['solar_power_utility'] = np.where(building_info.solar_power_capacity != '-', 1, 0)\n",
        "building_info['ess_utility'] = np.where(building_info.ess_capacity != '-', 1, 0)\n",
        "\n",
        "# 건물 정보 병합\n",
        "train = pd.merge(train, building_info, on='building_number', how='left')\n",
        "test = pd.merge(test, building_info, on='building_number', how='left')\n",
        "\n",
        "print(\"✅ 기본 전처리 완료\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Feature Engineering (작년 수상자 방식)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Feature Engineering 시작...\n",
            "✅ 기본 시간 피처 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 날짜/시간 변환 및 기본 시간 피처 생성\n",
        "print(\"🔧 Feature Engineering 시작...\")\n",
        "\n",
        "train['date_time'] = pd.to_datetime(train['date_time'], format='%Y%m%d %H')\n",
        "test['date_time'] = pd.to_datetime(test['date_time'], format='%Y%m%d %H')\n",
        "\n",
        "# 기본 시간 피처\n",
        "for df in [train, test]:\n",
        "    df['hour'] = df['date_time'].dt.hour\n",
        "    df['day'] = df['date_time'].dt.day\n",
        "    df['month'] = df['date_time'].dt.month\n",
        "    df['day_of_week'] = df['date_time'].dt.dayofweek\n",
        "\n",
        "print(\"✅ 기본 시간 피처 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 일별 온도 통계 피처 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 일별 온도 통계 피처 생성\n",
        "def calculate_day_values(dataframe, target_column, output_column, aggregation_func):\n",
        "    \"\"\"일별 통계값 계산 함수\"\"\"\n",
        "    result_dict = {}\n",
        "    grouped_temp = dataframe.groupby(['building_number', 'month', 'day'])[target_column].agg(aggregation_func)\n",
        "    \n",
        "    for (building, month, day), value in grouped_temp.items():\n",
        "        result_dict.setdefault(building, {}).setdefault(month, {})[day] = value\n",
        "    \n",
        "    dataframe[output_column] = [\n",
        "        result_dict.get(row['building_number'], {}).get(row['month'], {}).get(row['day'], None)\n",
        "        for _, row in dataframe.iterrows()\n",
        "    ]\n",
        "\n",
        "# 일별 온도 통계 피처 생성\n",
        "for df in [train, test]:\n",
        "    calculate_day_values(df, 'temperature', 'day_max_temperature', 'max')\n",
        "    calculate_day_values(df, 'temperature', 'day_mean_temperature', 'mean')\n",
        "    calculate_day_values(df, 'temperature', 'day_min_temperature', 'min')\n",
        "    df['day_temperature_range'] = df['day_max_temperature'] - df['day_min_temperature']\n",
        "\n",
        "print(\"✅ 일별 온도 통계 피처 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "제거할 이상치 개수: 68\n",
            "남은 행 개수: 203932\n",
            "✅ 이상치 제거 및 주기성 피처 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 이상치 제거 및 추가 피처 생성\n",
        "outlier_idx = train.index[train['power_consumption'] == 0].tolist()\n",
        "print(f\"제거할 이상치 개수: {len(outlier_idx)}\")\n",
        "train.drop(index=outlier_idx, inplace=True)\n",
        "print(f\"남은 행 개수: {train.shape[0]}\")\n",
        "\n",
        "# 공휴일 피처 생성\n",
        "holi_weekday = ['2024-06-06', '2024-08-15']\n",
        "train['holiday'] = np.where(\n",
        "    (train.day_of_week >= 5) | (train.date_time.dt.strftime('%Y-%m-%d').isin(holi_weekday)), 1, 0\n",
        ")\n",
        "test['holiday'] = np.where(\n",
        "    (test.day_of_week >= 5) | (test.date_time.dt.strftime('%Y-%m-%d').isin(holi_weekday)), 1, 0\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# 주기성 피처 생성 (Cyclical Features)\n",
        "for df in [train, test]:\n",
        "    # 시간 주기성\n",
        "    df['sin_hour'] = np.sin(2 * np.pi * df['hour'] / 23.0)\n",
        "    df['cos_hour'] = np.cos(2 * np.pi * df['hour'] / 23.0)\n",
        "    \n",
        "    # 날짜 주기성\n",
        "    df['sin_date'] = -np.sin(2 * np.pi * (df['month'] + df['day'] / 31) / 12)\n",
        "    df['cos_date'] = -np.cos(2 * np.pi * (df['month'] + df['day'] / 31) / 12)\n",
        "    \n",
        "    # 월 주기성\n",
        "    df['sin_month'] = -np.sin(2 * np.pi * df['month'] / 12.0)\n",
        "    df['cos_month'] = -np.cos(2 * np.pi * df['month'] / 12.0)\n",
        "    \n",
        "    # 요일 주기성\n",
        "    df['sin_dayofweek'] = -np.sin(2 * np.pi * (df['day_of_week'] + 1) / 7.0)\n",
        "    df['cos_dayofweek'] = -np.cos(2 * np.pi * (df['day_of_week'] + 1) / 7.0)\n",
        "\n",
        "print(\"✅ 이상치 제거 및 주기성 피처 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def create_inferred_holidays(df, building_info):\n",
        "    # 규칙이 없는 백화점 건물 번호 추출\n",
        "    department_store_buildings = [19,34,45,54,73,74,79,88,95]\n",
        "\n",
        "    # 백화점 건물에 대해 추정 휴일만 적용\n",
        "    for building_num in department_store_buildings:\n",
        "        building_data = df[df['building_number'] == building_num].copy()\n",
        "\n",
        "        if len(building_data) > 0:\n",
        "            # 일별 전력소비량 계산\n",
        "            building_data['date'] = building_data['date_time'].dt.date\n",
        "            daily_consumption = building_data.groupby('date')['power_consumption'].sum()\n",
        "\n",
        "            # 전체 평균 기준 임계치 (0.7배)\n",
        "            threshold = daily_consumption.mean() * 0.7\n",
        "            inferred_holiday_dates = daily_consumption[daily_consumption < threshold].index\n",
        "\n",
        "            # 추정 휴일을 해당 건물의 holiday 컬럼에 적용\n",
        "            for holiday_date in inferred_holiday_dates:\n",
        "                mask = (df['building_number'] == building_num) & (df['date_time'].dt.date == holiday_date)\n",
        "                df.loc[mask, 'holiday'] = 1\n",
        "\n",
        "    return df\n",
        "\n",
        "# 휴일 피처 생성\n",
        "train = create_inferred_holidays(train, building_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 특정 건물 휴일 규칙 적용 중... (달력 기준 주차)\n",
            "   건물 18: 매주 일요일 휴일 24개 적용\n",
            "   건물 27: 홀수 주 일요일 휴일 24개 적용\n",
            "   건물 40: 홀수 주 일요일 휴일 24개 적용\n",
            "   건물 59: 홀수 주 일요일 휴일 24개 적용\n",
            "   건물 63: 홀수 주 일요일 휴일 24개 적용\n",
            "   건물 29: 매달 10일 휴일 0개, 5번째 주 일요일 24개 적용\n",
            "   건물 32: 홀수 주 월요일 휴일 24개 적용\n",
            "✅ test 데이터에 백화점 추정 휴일 적용 완료\n",
            "✅ test 데이터에 특정 건물 휴일 규칙 적용 완료\n"
          ]
        }
      ],
      "source": [
        "# 매주 일요일 휴무 건물(18번) 추가 및 기존 규칙 유지\n",
        "\n",
        "def apply_specific_building_holidays(df):\n",
        "    \"\"\"\n",
        "    특정 건물들의 휴일 규칙을 적용하는 함수 (달력 기준 주차 계산)\n",
        "    - 18번 건물: 매주 일요일 휴무\n",
        "    - 27, 40, 63번 건물: 홀수 주 일요일 휴무\n",
        "    - 29번 건물: 매달 10일 + 5번째 주 일요일 휴무\n",
        "    - 32번 건물: 홀수 주 월요일 휴무\n",
        "    \"\"\"\n",
        "    print(\"🔧 특정 건물 휴일 규칙 적용 중... (달력 기준 주차)\")\n",
        "    department_store_buildings = building_info[building_info['building_type'] == 'Department Store']['building_number'].tolist()\n",
        "\n",
        "    # 백화점 건물에 해당하는 데이터만 holiday를 0으로 초기화\n",
        "    df.loc[df['building_number'].isin(department_store_buildings), 'holiday'] = 0\n",
        "\n",
        "    # 매주 일요일 휴무 건물 (18번)\n",
        "    every_sunday_buildings = [18]\n",
        "\n",
        "    # 홀수 주 일요일 휴무 건물들 (27, 40, 59, 63)\n",
        "    odd_week_sunday_buildings = [27, 40, 59, 63]\n",
        "\n",
        "    # 매달 10일 + 5번째 주 일요일 휴무 건물 (29)\n",
        "    special_holiday_building = [29]\n",
        "\n",
        "    # 홀수 주 월요일 휴무 건물 (32)\n",
        "    odd_week_monday_buildings = [32]\n",
        "\n",
        "    # 달력 기준 주차 계산 (일요일 시작)\n",
        "    def get_calendar_week_of_month(date_series):\n",
        "        \"\"\"달력 기준 주차 계산 (월의 첫날이 포함된 주를 1주차로)\"\"\"\n",
        "        result = []\n",
        "        for date in date_series:\n",
        "            first_day = date.replace(day=1)\n",
        "            first_day_weekday = first_day.weekday()\n",
        "            days_to_week_start = (first_day_weekday + 1) % 7  # 일요일 기준\n",
        "            week_start_of_first = first_day - pd.Timedelta(days=days_to_week_start)\n",
        "            days_since_first_week_start = (date - week_start_of_first).days\n",
        "            week_num = (days_since_first_week_start // 7) + 1\n",
        "            result.append(week_num)\n",
        "        return result\n",
        "\n",
        "    # 달력 기준 주차 계산\n",
        "    df['calendar_week_of_month'] = get_calendar_week_of_month(df['date_time'])\n",
        "\n",
        "    # 0. 매주 일요일 휴무 (18번 건물)\n",
        "    for building_num in every_sunday_buildings:\n",
        "        mask = (df['building_number'] == building_num) & (df['day_of_week'] == 6)\n",
        "        df.loc[mask, 'holiday'] = 1\n",
        "        count = mask.sum()\n",
        "        print(f\"   건물 {building_num}: 매주 일요일 휴일 {count}개 적용\")\n",
        "\n",
        "    # 1. 홀수 주 일요일 휴무 (27, 40, 59, 63번 건물)\n",
        "    for building_num in odd_week_sunday_buildings:\n",
        "        mask = (df['building_number'] == building_num) & \\\n",
        "               (df['day_of_week'] == 6) & \\\n",
        "               (df['calendar_week_of_month'] % 2 == 1)\n",
        "        df.loc[mask, 'holiday'] = 1\n",
        "        count = mask.sum()\n",
        "        print(f\"   건물 {building_num}: 홀수 주 일요일 휴일 {count}개 적용\")\n",
        "\n",
        "    # 2. 매달 10일 + 5번째 주 일요일 휴무 (29번 건물)\n",
        "    for building_num in special_holiday_building:\n",
        "        mask_10th = (df['building_number'] == building_num) & (df['date_time'].dt.day == 10)\n",
        "        df.loc[mask_10th, 'holiday'] = 1\n",
        "        count_10th = mask_10th.sum()\n",
        "        mask_5th_sunday = (df['building_number'] == building_num) & \\\n",
        "                          (df['day_of_week'] == 6) & \\\n",
        "                          (df['calendar_week_of_month'] == 5)\n",
        "        df.loc[mask_5th_sunday, 'holiday'] = 1\n",
        "        count_5th_sunday = mask_5th_sunday.sum()\n",
        "        print(f\"   건물 {building_num}: 매달 10일 휴일 {count_10th}개, 5번째 주 일요일 {count_5th_sunday}개 적용\")\n",
        "\n",
        "    # 3. 홀수 주 월요일 휴무 (32번 건물)\n",
        "    for building_num in odd_week_monday_buildings:\n",
        "        mask = (df['building_number'] == building_num) & \\\n",
        "               (df['day_of_week'] == 0) & \\\n",
        "               (df['calendar_week_of_month'] % 2 == 1)\n",
        "        df.loc[mask, 'holiday'] = 1\n",
        "        count = mask.sum()\n",
        "        print(f\"   건물 {building_num}: 홀수 주 월요일 휴일 {count}개 적용\")\n",
        "\n",
        "    # 임시 컬럼 제거\n",
        "    df.drop(['calendar_week_of_month'], axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# test 데이터에 특정 건물 휴일 규칙 적용\n",
        "test = apply_specific_building_holidays(test)\n",
        "\n",
        "print(\"✅ test 데이터에 백화점 추정 휴일 적용 완료\")\n",
        "print(\"✅ test 데이터에 특정 건물 휴일 규칙 적용 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 특정 건물들의 휴일 적용 결과 확인:\n",
            "건물 27번 (홀수 주 일요일) 휴일: 1일\n",
            "날짜: [datetime.date(2024, 8, 25)]...\n",
            "건물 29번 (매달 10일 + 5번째 주 일요일) 휴일: 1일\n",
            "날짜: [datetime.date(2024, 8, 25)]...\n",
            "건물 32번 (홀수 주 월요일) 휴일: 1일\n",
            "날짜: [datetime.date(2024, 8, 26)]...\n"
          ]
        }
      ],
      "source": [
        "# 특정 건물들의 휴일 적용 결과 확인\n",
        "print(\"🔍 특정 건물들의 휴일 적용 결과 확인:\")\n",
        "\n",
        "# 27번 건물 (홀수 주 일요일) 휴일 확인\n",
        "holiday_dates_27 = test.loc[(test['building_number'] == 27) & (test['holiday'] == 1), 'date_time'].dt.date\n",
        "unique_holiday_dates_27 = holiday_dates_27.drop_duplicates().tolist()\n",
        "print(f\"건물 27번 (홀수 주 일요일) 휴일: {len(unique_holiday_dates_27)}일\")\n",
        "print(f\"날짜: {unique_holiday_dates_27[:10]}...\")  # 처음 10개만 출력\n",
        "\n",
        "# 29번 건물 (매달 10일 + 5번째 주 일요일) 휴일 확인  \n",
        "holiday_dates_29 = test.loc[(test['building_number'] == 29) & (test['holiday'] == 1), 'date_time'].dt.date\n",
        "unique_holiday_dates_29 = holiday_dates_29.drop_duplicates().tolist()\n",
        "print(f\"건물 29번 (매달 10일 + 5번째 주 일요일) 휴일: {len(unique_holiday_dates_29)}일\")\n",
        "print(f\"날짜: {unique_holiday_dates_29[:10]}...\")  # 처음 10개만 출력\n",
        "\n",
        "# 32번 건물 (홀수 주 월요일) 휴일 확인\n",
        "holiday_dates_32 = test.loc[(test['building_number'] == 32) & (test['holiday'] == 1), 'date_time'].dt.date\n",
        "unique_holiday_dates_32 = holiday_dates_32.drop_duplicates().tolist()\n",
        "print(f\"건물 32번 (홀수 주 월요일) 휴일: {len(unique_holiday_dates_32)}일\")\n",
        "print(f\"날짜: {unique_holiday_dates_32[:10]}...\")  # 처음 10개만 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "건물 59번 (홀수 주 월요일) 휴일: 1일\n",
            "날짜: [datetime.date(2024, 8, 25)]...\n"
          ]
        }
      ],
      "source": [
        "n  = 59\n",
        "holiday_dates_n = test.loc[(test['building_number'] == n) & (test['holiday'] == 1), 'date_time'].dt.date\n",
        "unique_holiday_dates_n = holiday_dates_n.drop_duplicates().tolist()\n",
        "print(f\"건물 {n}번 (홀수 주 월요일) 휴일: {len(unique_holiday_dates_n)}일\")\n",
        "print(f\"날짜: {unique_holiday_dates_n[:10]}...\")  # 처음 10개만 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 기상 관련 파생 피처 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 기상 관련 파생 피처 생성\n",
        "def CDH(xs):\n",
        "    \"\"\"Cooling Degree Hours 계산\"\"\"\n",
        "    cumsum = np.cumsum(xs - 26)\n",
        "    return np.concatenate((cumsum[:11], cumsum[11:] - cumsum[:-11]))\n",
        "\n",
        "def calculate_and_add_cdh(dataframe):\n",
        "    \"\"\"건물별 CDH 계산 및 추가\"\"\"\n",
        "    cdhs = []\n",
        "    for i in range(1, 101):\n",
        "        temp = dataframe[dataframe['building_number'] == i]['temperature'].values\n",
        "        cdh = CDH(temp)\n",
        "        cdhs.append(cdh)\n",
        "    return np.concatenate(cdhs)\n",
        "\n",
        "# CDH, THI, WCT 피처 생성\n",
        "train['CDH'] = calculate_and_add_cdh(train)\n",
        "test['CDH'] = calculate_and_add_cdh(test)\n",
        "\n",
        "# THI (Temperature Humidity Index)\n",
        "train['THI'] = 9/5 * train['temperature'] - 0.55 * (1 - train['humidity']/100) * (9/5 * train['temperature'] - 26) + 32\n",
        "test['THI'] = 9/5 * test['temperature'] - 0.55 * (1 - test['humidity']/100) * (9/5 * test['temperature'] - 26) + 32\n",
        "\n",
        "# WCT (Wind Chill Temperature)\n",
        "train['WCT'] = 13.12 + 0.6125 * train['temperature'] - 11.37 * (train['windspeed']**0.16) + 0.3965 * (train['windspeed']**0.16) * train['temperature']\n",
        "test['WCT'] = 13.12 + 0.6125 * test['temperature'] - 11.37 * (test['windspeed']**0.16) + 0.3965 * (test['windspeed']**0.16) * test['temperature']\n",
        "\n",
        "print(\"✅ 기상 관련 파생 피처 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 전력 소비량 기반 통계 피처 생성 중...\n",
            "✅ 전력 소비량 기반 통계 피처 생성 완료\n",
            "최종 train 데이터 shape: (203932, 41)\n",
            "최종 test 데이터 shape: (16800, 38)\n"
          ]
        }
      ],
      "source": [
        "# 전력 소비량 기반 통계 피처 생성 (Target-like Features)\n",
        "print(\"📊 전력 소비량 기반 통계 피처 생성 중...\")\n",
        "\n",
        "# 건물별 시간대/요일별 평균 및 표준편차\n",
        "power_mean = pd.pivot_table(train, values='power_consumption', \n",
        "                           index=['building_number', 'hour', 'day_of_week'], \n",
        "                           aggfunc=np.mean).reset_index()\n",
        "power_mean.columns = ['building_number', 'hour', 'day_of_week', 'day_hour_mean']\n",
        "\n",
        "power_std = pd.pivot_table(train, values='power_consumption', \n",
        "                          index=['building_number', 'hour', 'day_of_week'], \n",
        "                          aggfunc=np.std).reset_index()\n",
        "power_std.columns = ['building_number', 'hour', 'day_of_week', 'day_hour_std']\n",
        "\n",
        "# 건물별 시간대별 평균 및 표준편차\n",
        "power_hour_mean = pd.pivot_table(train, values='power_consumption', \n",
        "                                index=['building_number', 'hour'], \n",
        "                                aggfunc=np.mean).reset_index()\n",
        "power_hour_mean.columns = ['building_number', 'hour', 'hour_mean']\n",
        "\n",
        "power_hour_std = pd.pivot_table(train, values='power_consumption', \n",
        "                               index=['building_number', 'hour'], \n",
        "                               aggfunc=np.std).reset_index()\n",
        "power_hour_std.columns = ['building_number', 'hour', 'hour_std']\n",
        "\n",
        "# 통계 피처 병합\n",
        "train = train.merge(power_mean, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
        "train = train.merge(power_std, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
        "train = train.merge(power_hour_mean, on=['building_number', 'hour'], how='left')\n",
        "train = train.merge(power_hour_std, on=['building_number', 'hour'], how='left')\n",
        "\n",
        "test = test.merge(power_mean, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
        "test = test.merge(power_std, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
        "test = test.merge(power_hour_mean, on=['building_number', 'hour'], how='left')\n",
        "test = test.merge(power_hour_std, on=['building_number', 'hour'], how='left')\n",
        "\n",
        "train = train.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "\n",
        "print(\"✅ 전력 소비량 기반 통계 피처 생성 완료\")\n",
        "print(f\"최종 train 데이터 shape: {train.shape}\")\n",
        "print(f\"최종 test 데이터 shape: {test.shape}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. 모델링용 데이터 준비\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 모델링용 데이터 준비 완료\n",
            "피처 수: 29\n",
            "건물 유형 수: 10\n",
            "건물 수: 100\n",
            "건물 유형: ['Hotel' 'Commercial' 'Hospital' 'University' 'Other Buildings'\n",
            " 'Apartment' 'Research Institute' 'Department Store' 'IDC' 'Public']\n",
            "건물 번호 범위: 1 ~ 100\n"
          ]
        }
      ],
      "source": [
        "# 모델링용 피처 선택 (작년 수상자 방식)\n",
        "drop_columns = [\n",
        "    'solar_power_capacity', 'ess_capacity', 'pcs_capacity',\n",
        "    'power_consumption', 'rainfall', 'sunshine', 'solar_radiation',\n",
        "    'hour', 'day', 'month', 'day_of_week', 'date_time'\n",
        "]\n",
        "\n",
        "X = train.drop(drop_columns, axis=1)\n",
        "Y = train[['building_type', 'power_consumption']]\n",
        "test_X = test.drop([col for col in drop_columns if col in test.columns], axis=1)\n",
        "\n",
        "print(f\"✅ 모델링용 데이터 준비 완료\")\n",
        "print(f\"피처 수: {X.shape[1]}\")\n",
        "print(f\"건물 유형 수: {len(X['building_type'].unique())}\")\n",
        "print(f\"건물 수: {len(X['building_number'].unique())}\")\n",
        "\n",
        "# 건물 유형 리스트\n",
        "type_list = X[\"building_type\"].unique()\n",
        "building_list = X[\"building_number\"].unique()\n",
        "\n",
        "print(f\"건물 유형: {type_list}\")\n",
        "print(f\"건물 번호 범위: {min(building_list)} ~ {max(building_list)}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. 건물 타입별 모델 (Model 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏢 Department Store 모델 훈련 시작...\n",
            "==================================================\n",
            "\n",
            "🔍 건물 유형: Department Store\n",
            "   📊 훈련 데이터: 32636개\n",
            "   📊 테스트 데이터: 2688개\n",
            "   🏆 평균 SMAPE: 3.6176\n",
            "\n",
            "🎯 Department Store 모델 전체 SMAPE: 3.6176\n",
            "✅ Department Store 모델 훈련 완료\n"
          ]
        }
      ],
      "source": [
        "## 백화점만 train\n",
        "print(\"🏢 Department Store 모델 훈련 시작...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "KFOLD_SPLITS = 7\n",
        "kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "# 백화점 전용 결과 저장용 DataFrame\n",
        "dept_mask_test = test_X['building_number'].isin(building_info[building_info['building_type'] == 'Department Store']['building_number'])\n",
        "dept_mask_train = X['building_number'].isin(building_info[building_info['building_type'] == 'Department Store']['building_number'])\n",
        "\n",
        "type_model_predictions = pd.DataFrame(index=test_X[dept_mask_test].index, columns=[\"answer\"], dtype=float)\n",
        "type_model_oof = pd.DataFrame(index=X[dept_mask_train].index, columns=[\"pred\"], dtype=float)\n",
        "\n",
        "type_model_scores = {}\n",
        "\n",
        "btype = \"Department Store\"\n",
        "print(f\"\\n🔍 건물 유형: {btype}\")\n",
        "\n",
        "# 해당 유형 데이터 필터링\n",
        "x = X[X['building_type'] == btype].copy()\n",
        "y = Y[Y['building_type'] == btype]['power_consumption'].copy()\n",
        "xt = test_X[test_X['building_type'] == btype].copy()\n",
        "\n",
        "print(f\"   📊 훈련 데이터: {len(x)}개\")\n",
        "print(f\"   📊 테스트 데이터: {len(xt)}개\")\n",
        "\n",
        "# 건물 번호 원-핫 인코딩\n",
        "x = pd.get_dummies(x, columns=[\"building_number\"], drop_first=False)\n",
        "xt = pd.get_dummies(xt, columns=[\"building_number\"], drop_first=False)\n",
        "\n",
        "# 테스트 데이터에 없는 컬럼 처리\n",
        "xt = xt.reindex(columns=x.columns, fill_value=0)\n",
        "\n",
        "# building_type 컬럼 제거\n",
        "x = x.drop(columns=[\"building_type\"])\n",
        "xt = xt.drop(columns=[\"building_type\"])\n",
        "\n",
        "# K-Fold 교차 검증\n",
        "preds_valid = pd.Series(index=y.index, dtype=float)\n",
        "preds_test = []\n",
        "fold_scores = []\n",
        "\n",
        "x_values = x.values\n",
        "y_values = y.values\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(kf.split(x_values), 1):\n",
        "    X_tr, X_va = x_values[tr_idx], x_values[va_idx]\n",
        "    y_tr, y_va = y_values[tr_idx], y_values[va_idx]\n",
        "    \n",
        "    # 로그 변환\n",
        "    y_tr_log = np.log(y_tr)\n",
        "    y_va_log = np.log(y_va)\n",
        "    \n",
        "    # XGBoost 모델 훈련\n",
        "    model = XGBRegressor(\n",
        "        learning_rate=0.05,\n",
        "        n_estimators=5000,\n",
        "        max_depth=10,\n",
        "        subsample=0.7,\n",
        "        colsample_bytree=0.5,\n",
        "        min_child_weight=3,\n",
        "        random_state=RANDOM_SEED,\n",
        "        objective=weighted_mse(3),\n",
        "        early_stopping_rounds=100,\n",
        "    )\n",
        "    \n",
        "    model.fit(\n",
        "        X_tr, y_tr_log,\n",
        "        eval_set=[(X_va, y_va_log)],\n",
        "        eval_metric=custom_smape,\n",
        "        verbose=False,\n",
        "    )\n",
        "    \n",
        "    # 검증 예측 (로그 역변환)\n",
        "    va_pred = np.exp(model.predict(X_va))\n",
        "    preds_valid.iloc[va_idx] = va_pred\n",
        "    \n",
        "    # 성능 계산\n",
        "    fold_smape = smape(y_va, va_pred)\n",
        "    fold_scores.append(fold_smape)\n",
        "    \n",
        "    # 테스트 예측\n",
        "    preds_test.append(np.exp(model.predict(xt.values)))\n",
        "\n",
        "# 검증 예측 저장\n",
        "type_model_oof.loc[preds_valid.index, \"pred\"] = preds_valid\n",
        "\n",
        "# 테스트 예측 (앙상블 평균) 저장\n",
        "type_model_predictions.loc[xt.index, \"answer\"] = np.mean(preds_test, axis=0)\n",
        "\n",
        "# 성능 저장\n",
        "avg_smape = np.mean(fold_scores)\n",
        "type_model_scores[btype] = avg_smape\n",
        "\n",
        "print(f\"   🏆 평균 SMAPE: {avg_smape:.4f}\")\n",
        "\n",
        "# 백화점 성능 계산 (NaN 값 제거)\n",
        "dept_y_true = Y[dept_mask_train][\"power_consumption\"].values\n",
        "dept_y_pred = type_model_oof[\"pred\"].values\n",
        "\n",
        "# NaN 값 제거\n",
        "valid_mask = ~(pd.isna(dept_y_true) | pd.isna(dept_y_pred))\n",
        "if np.sum(valid_mask) > 0:\n",
        "    total_type_smape = smape(dept_y_true[valid_mask], dept_y_pred[valid_mask])\n",
        "else:\n",
        "    total_type_smape = float('nan')\n",
        "\n",
        "print(f\"\\n🎯 Department Store 모델 전체 SMAPE: {total_type_smape:.4f}\")\n",
        "print(\"✅ Department Store 모델 훈련 완료\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. 건물별 개별 모델 (Model 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏠 건물별 개별 모델 훈련 시작...\n",
            "==================================================\n",
            "\n",
            "🏢 건물 18 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 3.1663\n",
            "\n",
            "🏢 건물 19 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 4.6571\n",
            "\n",
            "🏢 건물 27 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 3.1070\n",
            "\n",
            "🏢 건물 29 훈련 중...\n",
            "   📊 훈련 데이터: 2037개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 1.9587\n",
            "\n",
            "🏢 건물 32 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 3.3886\n",
            "\n",
            "🏢 건물 34 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 1.9461\n",
            "\n",
            "🏢 건물 40 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 2.9426\n",
            "   ⏳ 진행률: 250.0% | 평균 SMAPE: 3.0238\n",
            "\n",
            "🏢 건물 45 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 3.3811\n",
            "\n",
            "🏢 건물 54 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 6.4161\n",
            "\n",
            "🏢 건물 59 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 3.8745\n",
            "\n",
            "🏢 건물 63 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 2.7206\n",
            "\n",
            "🏢 건물 73 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 2.8266\n",
            "\n",
            "🏢 건물 74 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 3.7127\n",
            "\n",
            "🏢 건물 79 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 3.1505\n",
            "\n",
            "🏢 건물 88 훈련 중...\n",
            "   📊 훈련 데이터: 2039개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 3.4799\n",
            "\n",
            "🏢 건물 95 훈련 중...\n",
            "   📊 훈련 데이터: 2040개\n",
            "   📊 테스트 데이터: 168개\n",
            "   🏆 평균 SMAPE: 4.6334\n",
            "\n",
            "🎯 건물별 개별 모델 전체 SMAPE: 3.4604\n",
            "✅ 건물별 개별 모델 훈련 완료\n"
          ]
        }
      ],
      "source": [
        "## 백화점 만 train\n",
        "\n",
        "print(\"🏠 건물별 개별 모델 훈련 시작...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 'Department Store' 건물 번호만 추출\n",
        "department_store_buildings = building_info[building_info['building_type'] == 'Department Store']['building_number'].tolist()\n",
        "\n",
        "# 백화점 전용 결과 저장용 DataFrame (기존에 정의된 마스크 재사용)\n",
        "individual_model_predictions = pd.DataFrame(index=test_X[dept_mask_test].index, columns=[\"answer\"], dtype=float)\n",
        "individual_model_oof = pd.DataFrame(index=X[dept_mask_train].index, columns=[\"pred\"], dtype=float)\n",
        "\n",
        "individual_model_scores = {}\n",
        "\n",
        "for building_num in sorted(department_store_buildings):\n",
        "    print(f\"\\n🏢 건물 {building_num} 훈련 중...\")\n",
        "    \n",
        "    # 해당 건물 데이터 필터링\n",
        "    x = X[X['building_number'] == building_num].copy()\n",
        "    y = Y[Y.index.isin(x.index)]['power_consumption'].copy()\n",
        "    xt = test_X[test_X['building_number'] == building_num].copy()\n",
        "    \n",
        "    print(f\"   📊 훈련 데이터: {len(x)}개\")\n",
        "    print(f\"   📊 테스트 데이터: {len(xt)}개\")\n",
        "    \n",
        "    # 불필요한 컬럼 제거 (건물번호, 건물유형)\n",
        "    feature_cols = [col for col in x.columns if col not in ['building_number', 'building_type']]\n",
        "    x_features = x[feature_cols].copy()\n",
        "    xt_features = xt[feature_cols].copy()\n",
        "    \n",
        "    # K-Fold 교차 검증\n",
        "    preds_valid = pd.Series(index=y.index, dtype=float)\n",
        "    preds_test = []\n",
        "    fold_scores = []\n",
        "    \n",
        "    x_values = x_features.values\n",
        "    y_values = y.values\n",
        "    \n",
        "    for fold, (tr_idx, va_idx) in enumerate(kf.split(x_values), 1):\n",
        "        X_tr, X_va = x_values[tr_idx], x_values[va_idx]\n",
        "        y_tr, y_va = y_values[tr_idx], y_values[va_idx]\n",
        "        \n",
        "        # 로그 변환\n",
        "        y_tr_log = np.log(y_tr)\n",
        "        y_va_log = np.log(y_va)\n",
        "        \n",
        "        # XGBoost 모델 훈련\n",
        "        model = XGBRegressor(\n",
        "            learning_rate=0.05,\n",
        "            n_estimators=5000,\n",
        "            max_depth=10,\n",
        "            subsample=0.7,\n",
        "            colsample_bytree=0.5,\n",
        "            min_child_weight=3,\n",
        "            random_state=RANDOM_SEED,\n",
        "            objective=weighted_mse(3),\n",
        "            early_stopping_rounds=100,\n",
        "        )\n",
        "        \n",
        "        model.fit(\n",
        "            X_tr, y_tr_log,\n",
        "            eval_set=[(X_va, y_va_log)],\n",
        "            eval_metric=custom_smape,\n",
        "            verbose=False,\n",
        "        )\n",
        "        \n",
        "        # 검증 예측 (로그 역변환)\n",
        "        va_pred = np.exp(model.predict(X_va))\n",
        "        preds_valid.iloc[va_idx] = va_pred\n",
        "        \n",
        "        # 성능 계산\n",
        "        fold_smape = smape(y_va, va_pred)\n",
        "        fold_scores.append(fold_smape)\n",
        "        \n",
        "        # 테스트 예측\n",
        "        preds_test.append(np.exp(model.predict(xt_features.values)))\n",
        "    \n",
        "    # 검증 예측 저장\n",
        "    individual_model_oof.loc[preds_valid.index, \"pred\"] = preds_valid\n",
        "    \n",
        "    # 테스트 예측 (앙상블 평균) 저장\n",
        "    individual_model_predictions.loc[xt.index, \"answer\"] = np.mean(preds_test, axis=0)\n",
        "    \n",
        "    # 성능 저장\n",
        "    avg_smape = np.mean(fold_scores)\n",
        "    individual_model_scores[building_num] = avg_smape\n",
        "    \n",
        "    print(f\"   🏆 평균 SMAPE: {avg_smape:.4f}\")\n",
        "    \n",
        "    # 진행률 출력 (10개마다)\n",
        "    if building_num % 10 == 0:\n",
        "        progress = building_num / len(department_store_buildings) * 100\n",
        "        avg_score = np.mean(list(individual_model_scores.values()))\n",
        "        print(f\"   ⏳ 진행률: {progress:.1f}% | 평균 SMAPE: {avg_score:.4f}\")\n",
        "\n",
        "# 백화점 개별 모델 성능 계산 (NaN 값 제거)\n",
        "dept_y_true_individual = Y[dept_mask_train][\"power_consumption\"].values\n",
        "dept_y_pred_individual = individual_model_oof[\"pred\"].values\n",
        "\n",
        "# NaN 값 제거\n",
        "valid_mask_individual = ~(pd.isna(dept_y_true_individual) | pd.isna(dept_y_pred_individual))\n",
        "if np.sum(valid_mask_individual) > 0:\n",
        "    total_individual_smape = smape(dept_y_true_individual[valid_mask_individual], dept_y_pred_individual[valid_mask_individual])\n",
        "else:\n",
        "    total_individual_smape = float('nan')\n",
        "\n",
        "print(f\"\\n🎯 건물별 개별 모델 전체 SMAPE: {total_individual_smape:.4f}\")\n",
        "print(\"✅ 건물별 개별 모델 훈련 완료\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. 백화점 앙상블 모델 + 기존 결과 결합\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 백화점 앙상블 모델 + 기존 결과 결합 중...\n",
            "==================================================\n",
            "📂 기존 앙상블 결과 로드 중...\n",
            "✅ 기존 제출 파일 로드 완료: (16800, 2)\n",
            "🏢 백화점 건물 번호: [18, 19, 27, 29, 32, 34, 40, 45, 54, 59, 63, 73, 74, 79, 88, 95]\n",
            "\n",
            "📊 백화점 앙상블 가중치:\n",
            "   개별 건물 모델: 70.0%\n",
            "   건물 타입별 모델: 30.0%\n",
            "📊 앙상블 전 데이터 상태 확인:\n",
            "   개별 모델 예측값 개수: 2688\n",
            "   타입별 모델 예측값 개수: 2688\n",
            "   개별 모델 OOF 예측값 개수: 32636\n",
            "   타입별 모델 OOF 예측값 개수: 32636\n",
            "   앙상블 후 검증 예측값 개수: 32636\n",
            "   앙상블 후 테스트 예측값 개수: 2688\n",
            "📊 백화점 테스트 데이터 인덱스 수: 2688\n",
            "📊 예측값 교체 과정:\n",
            "   백화점 테스트 인덱스 범위: 2856 ~ 15959\n",
            "   앙상블 예측값 인덱스 범위: 2856 ~ 15959\n",
            "   성공적으로 교체된 예측값: 2688개\n",
            "\n",
            "📊 성능 계산을 위한 데이터 확인:\n",
            "   백화점 훈련 인덱스 수: 32636\n",
            "   실제값 개수: 32636\n",
            "   예측값 개수: 32636\n",
            "   유효한 데이터 개수: 32636\n",
            "\n",
            "🏆 백화점 성능 비교:\n",
            "   백화점 타입별 모델 SMAPE: 3.6176\n",
            "   백화점 개별 모델 SMAPE: 3.4604\n",
            "   백화점 앙상블 모델 SMAPE: 3.3549\n",
            "\n",
            "📈 백화점 성능 향상:\n",
            "   vs 타입별 모델: +0.2628 SMAPE\n",
            "   vs 개별 모델: +0.1055 SMAPE\n",
            "\n",
            "🎉 백화점 앙상블이 개별 모델들보다 우수한 성능을 보입니다!\n",
            "\n",
            "✅ 백화점 앙상블 + 기존 결과 결합 완료\n",
            "📊 최종 제출 파일:\n",
            "   - 백화점 건물: 새로운 앙상블 예측값 (2688개)\n",
            "   - 기타 건물: 기존 앙상블 예측값 (14112개)\n"
          ]
        }
      ],
      "source": [
        "print(\"🎯 백화점 앙상블 모델 + 기존 결과 결합 중...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. 기존 앙상블 결과 로드\n",
        "print(\"📂 기존 앙상블 결과 로드 중...\")\n",
        "existing_submission = pd.read_csv('result_csv/ensemble_submission.csv')\n",
        "print(f\"✅ 기존 제출 파일 로드 완료: {existing_submission.shape}\")\n",
        "\n",
        "# 2. 백화점 건물 번호 추출\n",
        "department_store_buildings = building_info[building_info['building_type'] == 'Department Store']['building_number'].tolist()\n",
        "print(f\"🏢 백화점 건물 번호: {sorted(department_store_buildings)}\")\n",
        "\n",
        "# 3. 백화점에 대한 앙상블 가중치 설정\n",
        "individual_weight = 0.7  # 개별 건물 모델 가중치\n",
        "type_weight = 0.3        # 건물 타입별 모델 가중치\n",
        "\n",
        "print(f\"\\n📊 백화점 앙상블 가중치:\")\n",
        "print(f\"   개별 건물 모델: {individual_weight * 100}%\")\n",
        "print(f\"   건물 타입별 모델: {type_weight * 100}%\")\n",
        "\n",
        "# 4. 백화점 건물에 대해서만 앙상블 수행\n",
        "department_store_mask = test_X['building_number'].isin(department_store_buildings)\n",
        "department_train_mask = X['building_number'].isin(department_store_buildings)\n",
        "\n",
        "# 데이터 상태 확인\n",
        "print(f\"📊 앙상블 전 데이터 상태 확인:\")\n",
        "print(f\"   개별 모델 예측값 개수: {len(individual_model_predictions)}\")\n",
        "print(f\"   타입별 모델 예측값 개수: {len(type_model_predictions)}\")\n",
        "print(f\"   개별 모델 OOF 예측값 개수: {len(individual_model_oof)}\")\n",
        "print(f\"   타입별 모델 OOF 예측값 개수: {len(type_model_oof)}\")\n",
        "\n",
        "# 백화점 검증 데이터 앙상블 (성능 평가용)\n",
        "ensemble_oof_dept = (\n",
        "    individual_model_oof[\"pred\"] * individual_weight + \n",
        "    type_model_oof[\"pred\"] * type_weight\n",
        ")\n",
        "\n",
        "# 백화점 테스트 데이터 앙상블\n",
        "ensemble_predictions_dept = (\n",
        "    individual_model_predictions[\"answer\"] * individual_weight + \n",
        "    type_model_predictions[\"answer\"] * type_weight\n",
        ")\n",
        "\n",
        "print(f\"   앙상블 후 검증 예측값 개수: {len(ensemble_oof_dept)}\")\n",
        "print(f\"   앙상블 후 테스트 예측값 개수: {len(ensemble_predictions_dept)}\")\n",
        "\n",
        "# 5. 최종 제출 파일 생성 (백화점은 새로운 값, 나머지는 기존 값)\n",
        "final_submission = existing_submission.copy()\n",
        "\n",
        "# 백화점 건물에 해당하는 인덱스 찾기\n",
        "dept_test_indices = test_X[department_store_mask].index\n",
        "print(f\"📊 백화점 테스트 데이터 인덱스 수: {len(dept_test_indices)}\")\n",
        "\n",
        "# 백화점 건물 예측값을 새로운 앙상블 결과로 교체\n",
        "print(f\"📊 예측값 교체 과정:\")\n",
        "print(f\"   백화점 테스트 인덱스 범위: {dept_test_indices.min()} ~ {dept_test_indices.max()}\")\n",
        "print(f\"   앙상블 예측값 인덱스 범위: {ensemble_predictions_dept.index.min()} ~ {ensemble_predictions_dept.index.max()}\")\n",
        "\n",
        "replacement_count = 0\n",
        "for idx in dept_test_indices:\n",
        "    if idx < len(final_submission) and idx in ensemble_predictions_dept.index:\n",
        "        if pd.notna(ensemble_predictions_dept.loc[idx]):\n",
        "            final_submission.loc[idx, 'answer'] = ensemble_predictions_dept.loc[idx]\n",
        "            replacement_count += 1\n",
        "        else:\n",
        "            print(f\"   ⚠️ 인덱스 {idx}의 예측값이 NaN입니다.\")\n",
        "    else:\n",
        "        print(f\"   ⚠️ 인덱스 {idx}를 찾을 수 없습니다.\")\n",
        "\n",
        "print(f\"   성공적으로 교체된 예측값: {replacement_count}개\")\n",
        "\n",
        "# 6. 백화점 성능 계산\n",
        "# 백화점 훈련 데이터의 실제값과 앙상블 예측값 추출\n",
        "dept_train_indices = X[department_train_mask].index\n",
        "dept_y_true = Y.loc[dept_train_indices, \"power_consumption\"].values\n",
        "dept_y_pred = ensemble_oof_dept.values\n",
        "\n",
        "print(f\"\\n📊 성능 계산을 위한 데이터 확인:\")\n",
        "print(f\"   백화점 훈련 인덱스 수: {len(dept_train_indices)}\")\n",
        "print(f\"   실제값 개수: {len(dept_y_true)}\")\n",
        "print(f\"   예측값 개수: {len(dept_y_pred)}\")\n",
        "\n",
        "# NaN 값 제거\n",
        "valid_mask = ~(pd.isna(dept_y_true) | pd.isna(dept_y_pred))\n",
        "print(f\"   유효한 데이터 개수: {np.sum(valid_mask)}\")\n",
        "\n",
        "if np.sum(valid_mask) > 0:\n",
        "    dept_y_true_clean = dept_y_true[valid_mask]\n",
        "    dept_y_pred_clean = dept_y_pred[valid_mask]\n",
        "    \n",
        "    ensemble_smape_dept = smape(dept_y_true_clean, dept_y_pred_clean)\n",
        "    \n",
        "    print(f\"\\n🏆 백화점 성능 비교:\")\n",
        "    if not np.isnan(total_type_smape):\n",
        "        print(f\"   백화점 타입별 모델 SMAPE: {total_type_smape:.4f}\")\n",
        "    else:\n",
        "        print(f\"   백화점 타입별 모델 SMAPE: 계산 불가\")\n",
        "        \n",
        "    if not np.isnan(total_individual_smape):\n",
        "        print(f\"   백화점 개별 모델 SMAPE: {total_individual_smape:.4f}\")\n",
        "    else:\n",
        "        print(f\"   백화점 개별 모델 SMAPE: 계산 불가\")\n",
        "        \n",
        "    print(f\"   백화점 앙상블 모델 SMAPE: {ensemble_smape_dept:.4f}\")\n",
        "    \n",
        "    # 성능 향상 확인 (NaN이 아닌 경우만)\n",
        "    if not np.isnan(total_type_smape) and not np.isnan(total_individual_smape):\n",
        "        improvement_vs_type = total_type_smape - ensemble_smape_dept\n",
        "        improvement_vs_individual = total_individual_smape - ensemble_smape_dept\n",
        "        \n",
        "        print(f\"\\n📈 백화점 성능 향상:\")\n",
        "        print(f\"   vs 타입별 모델: {improvement_vs_type:+.4f} SMAPE\")\n",
        "        print(f\"   vs 개별 모델: {improvement_vs_individual:+.4f} SMAPE\")\n",
        "        \n",
        "        if ensemble_smape_dept < min(total_type_smape, total_individual_smape):\n",
        "            print(\"\\n🎉 백화점 앙상블이 개별 모델들보다 우수한 성능을 보입니다!\")\n",
        "        else:\n",
        "            print(\"\\n⚠️ 백화점 앙상블 성능이 기대보다 낮습니다. 가중치 조정을 고려해보세요.\")\n",
        "else:\n",
        "    print(\"⚠️ 백화점 성능 계산 중 유효한 데이터가 없습니다.\")\n",
        "    ensemble_smape_dept = float('nan')\n",
        "\n",
        "print(f\"\\n✅ 백화점 앙상블 + 기존 결과 결합 완료\")\n",
        "print(f\"📊 최종 제출 파일:\")\n",
        "print(f\"   - 백화점 건물: 새로운 앙상블 예측값 ({len(dept_test_indices)}개)\")\n",
        "print(f\"   - 기타 건물: 기존 앙상블 예측값 ({len(final_submission) - len(dept_test_indices)}개)\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 9. 최종 제출 파일 생성 및 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📝 최종 제출 파일 생성 중...\n",
            "✅ 최종 제출 파일 저장: result_csv/ensemble_submission_with_dept_holiday.csv\n"
          ]
        }
      ],
      "source": [
        "print(\"📝 최종 제출 파일 생성 중...\")\n",
        "\n",
        "# 음수값 처리 (전력 소비량은 음수가 될 수 없음)\n",
        "final_submission[\"answer\"] = np.maximum(final_submission[\"answer\"], 0)\n",
        "\n",
        "# 최종 제출 파일 저장\n",
        "final_submission.to_csv('result_csv/ensemble_submission_with_dept_holiday3.csv', index=False)\n",
        "\n",
        "print(\"✅ 최종 제출 파일 저장: result_csv/ensemble_submission_with_dept_holiday.csv\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sd2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
