{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 ModernTCN 전력 소비량 예측 모델 시작!\n",
            "📱 사용 디바이스: cuda\n",
            "==================================================\n",
            "✅ ModernTCN 모델 및 유틸리티 함수 정의 완료\n"
          ]
        }
      ],
      "source": [
        "# ModernTCN 전력 소비량 예측 모델\n",
        "# XGBoost 대신 ModernTCN-short-term 사용\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import pickle\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "import random as rn\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# 시드 설정\n",
        "RANDOM_SEED = 2025\n",
        "np.random.seed(RANDOM_SEED)\n",
        "rn.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(RANDOM_SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧪 전체 데이터 기간 확인...\n",
            "📅 전체 train 데이터 기간: 2024-06-01 00:00:00 ~ 2024-08-24 23:00:00\n",
            "📊 전체 train 데이터 수: 204000개\n",
            "📊 총 기간: 84일\n",
            "📊 총 주차: 12주\n",
            "\\n📊 건물 1 데이터: 2040개\n",
            "📅 건물 1 기간: 2024-06-01 00:00:00 ~ 2024-08-24 23:00:00\n",
            "📊 건물 1 총 기간: 84일\n",
            "📊 건물 1 총 주차: 12주\n"
          ]
        }
      ],
      "source": [
        "# 전체 데이터 기간 확인\n",
        "print(\"🧪 전체 데이터 기간 확인...\")\n",
        "\n",
        "# 데이터 로드\n",
        "train = pd.read_csv('data/train.csv')\n",
        "train = train.rename(columns={'일시': 'date_time'})\n",
        "train['date_time'] = pd.to_datetime(train['date_time'], format='%Y%m%d %H')\n",
        "\n",
        "print(f\"📅 전체 train 데이터 기간: {train['date_time'].min()} ~ {train['date_time'].max()}\")\n",
        "print(f\"📊 전체 train 데이터 수: {len(train)}개\")\n",
        "print(f\"📊 총 기간: {(train['date_time'].max() - train['date_time'].min()).days}일\")\n",
        "print(f\"📊 총 주차: {(train['date_time'].max() - train['date_time'].min()).days // 7}주\")\n",
        "\n",
        "# 건물 1개의 전체 데이터로 테스트\n",
        "building_1_data = train[train['건물번호'] == 1].copy()\n",
        "print(f\"\\\\n📊 건물 1 데이터: {len(building_1_data)}개\")\n",
        "print(f\"📅 건물 1 기간: {building_1_data['date_time'].min()} ~ {building_1_data['date_time'].max()}\")\n",
        "print(f\"📊 건물 1 총 기간: {(building_1_data['date_time'].max() - building_1_data['date_time'].min()).days}일\")\n",
        "print(f\"📊 건물 1 총 주차: {(building_1_data['date_time'].max() - building_1_data['date_time'].min()).days // 7}주\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. 평가 함수 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 평가 함수 정의 완료\n"
          ]
        }
      ],
      "source": [
        "def smape(gt, preds):\n",
        "    \"\"\"SMAPE (Symmetric Mean Absolute Percentage Error) 계산\"\"\"\n",
        "    gt = np.array(gt)\n",
        "    preds = np.array(preds)\n",
        "    v = 2 * abs(preds - gt) / (abs(preds) + abs(gt))\n",
        "    score = np.mean(v) * 100\n",
        "    return score\n",
        "    \n",
        "def weighted_mse(alpha=1):\n",
        "    \"\"\"가중 MSE 손실 함수 (Under-prediction에 더 큰 페널티)\"\"\"\n",
        "    def weighted_mse_fixed(label, pred):\n",
        "        residual = (label - pred).astype(\"float\")\n",
        "        grad = np.where(residual > 0, -2 * alpha * residual, -2 * residual)\n",
        "        hess = np.where(residual > 0, 2 * alpha, 2.0)\n",
        "        return grad, hess\n",
        "    return weighted_mse_fixed\n",
        "\n",
        "def custom_smape(preds, dtrain):\n",
        "    \"\"\"XGBoost용 SMAPE 평가 함수\"\"\"\n",
        "    labels = dtrain.get_label()\n",
        "    return 'custom_smape', np.mean(2 * abs(preds - labels) / (abs(preds) + abs(labels))) * 100\n",
        "\n",
        "print(\"✅ 평가 함수 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. 데이터 로드 및 기본 전처리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 데이터 로드 중...\n",
            "✅ Train 데이터: (204000, 10)\n",
            "✅ Test 데이터: (16800, 7)\n",
            "✅ Building info: (100, 7)\n",
            "✅ 기본 전처리 완료\n"
          ]
        }
      ],
      "source": [
        "# 데이터 로드\n",
        "print(\"📊 데이터 로드 중...\")\n",
        "train = pd.read_csv('data/train.csv')\n",
        "test = pd.read_csv('data/test.csv')\n",
        "building_info = pd.read_csv('data/building_info.csv')\n",
        "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
        "\n",
        "print(f\"✅ Train 데이터: {train.shape}\")\n",
        "print(f\"✅ Test 데이터: {test.shape}\")\n",
        "print(f\"✅ Building info: {building_info.shape}\")\n",
        "\n",
        "# 컬럼명 영어로 변경 (작년 수상자 방식)\n",
        "train = train.rename(columns={\n",
        "    '건물번호': 'building_number',\n",
        "    '일시': 'date_time',\n",
        "    '기온(°C)': 'temperature',\n",
        "    '강수량(mm)': 'rainfall',\n",
        "    '풍속(m/s)': 'windspeed',\n",
        "    '습도(%)': 'humidity',\n",
        "    '일조(hr)': 'sunshine',\n",
        "    '일사(MJ/m2)': 'solar_radiation',\n",
        "    '전력소비량(kWh)': 'power_consumption'\n",
        "})\n",
        "train.drop('num_date_time', axis=1, inplace=True)\n",
        "\n",
        "test = test.rename(columns={\n",
        "    '건물번호': 'building_number',\n",
        "    '일시': 'date_time',\n",
        "    '기온(°C)': 'temperature',\n",
        "    '강수량(mm)': 'rainfall',\n",
        "    '풍속(m/s)': 'windspeed',\n",
        "    '습도(%)': 'humidity',\n",
        "    '일조(hr)': 'sunshine',\n",
        "    '일사(MJ/m2)': 'solar_radiation'\n",
        "})\n",
        "test.drop('num_date_time', axis=1, inplace=True)\n",
        "\n",
        "building_info = building_info.rename(columns={\n",
        "    '건물번호': 'building_number',\n",
        "    '건물유형': 'building_type',\n",
        "    '연면적(m2)': 'total_area',\n",
        "    '냉방면적(m2)': 'cooling_area',\n",
        "    '태양광용량(kW)': 'solar_power_capacity',\n",
        "    'ESS저장용량(kWh)': 'ess_capacity',\n",
        "    'PCS용량(kW)': 'pcs_capacity'\n",
        "})\n",
        "\n",
        "# 건물 유형 영어로 번역\n",
        "translation_dict = {\n",
        "    '건물기타': 'Other Buildings',\n",
        "    '공공': 'Public',\n",
        "    '학교': 'University',\n",
        "    '백화점': 'Department Store',\n",
        "    '병원': 'Hospital',\n",
        "    '상용': 'Commercial',\n",
        "    '아파트': 'Apartment',\n",
        "    '연구소': 'Research Institute',\n",
        "    'IDC(전화국)': 'IDC',\n",
        "    '호텔': 'Hotel'\n",
        "}\n",
        "building_info['building_type'] = building_info['building_type'].replace(translation_dict)\n",
        "\n",
        "# 태양광/ESS 설비 유무 피처 생성\n",
        "building_info['solar_power_utility'] = np.where(building_info.solar_power_capacity != '-', 1, 0)\n",
        "building_info['ess_utility'] = np.where(building_info.ess_capacity != '-', 1, 0)\n",
        "\n",
        "# 건물 정보 병합\n",
        "train = pd.merge(train, building_info, on='building_number', how='left')\n",
        "test = pd.merge(test, building_info, on='building_number', how='left')\n",
        "\n",
        "print(\"✅ 기본 전처리 완료\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Feature Engineering (작년 수상자 방식)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Feature Engineering 시작...\n",
            "✅ 기본 시간 피처 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 날짜/시간 변환 및 기본 시간 피처 생성\n",
        "print(\"🔧 Feature Engineering 시작...\")\n",
        "\n",
        "train['date_time'] = pd.to_datetime(train['date_time'], format='%Y%m%d %H')\n",
        "test['date_time'] = pd.to_datetime(test['date_time'], format='%Y%m%d %H')\n",
        "\n",
        "# 기본 시간 피처\n",
        "for df in [train, test]:\n",
        "    df['hour'] = df['date_time'].dt.hour\n",
        "    df['day'] = df['date_time'].dt.day\n",
        "    df['month'] = df['date_time'].dt.month\n",
        "    df['day_of_week'] = df['date_time'].dt.dayofweek\n",
        "\n",
        "print(\"✅ 기본 시간 피처 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 일별 온도 통계 피처 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 일별 온도 통계 피처 생성\n",
        "def calculate_day_values(dataframe, target_column, output_column, aggregation_func):\n",
        "    \"\"\"일별 통계값 계산 함수\"\"\"\n",
        "    result_dict = {}\n",
        "    grouped_temp = dataframe.groupby(['building_number', 'month', 'day'])[target_column].agg(aggregation_func)\n",
        "    \n",
        "    for (building, month, day), value in grouped_temp.items():\n",
        "        result_dict.setdefault(building, {}).setdefault(month, {})[day] = value\n",
        "    \n",
        "    dataframe[output_column] = [\n",
        "        result_dict.get(row['building_number'], {}).get(row['month'], {}).get(row['day'], None)\n",
        "        for _, row in dataframe.iterrows()\n",
        "    ]\n",
        "\n",
        "# 일별 온도 통계 피처 생성\n",
        "for df in [train, test]:\n",
        "    calculate_day_values(df, 'temperature', 'day_max_temperature', 'max')\n",
        "    calculate_day_values(df, 'temperature', 'day_mean_temperature', 'mean')\n",
        "    calculate_day_values(df, 'temperature', 'day_min_temperature', 'min')\n",
        "    df['day_temperature_range'] = df['day_max_temperature'] - df['day_min_temperature']\n",
        "\n",
        "print(\"✅ 일별 온도 통계 피처 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "제거할 이상치 개수: 68\n",
            "남은 행 개수: 203932\n"
          ]
        }
      ],
      "source": [
        "# 이상치 제거 및 추가 피처 생성 (0 제거)\n",
        "outlier_idx = train.index[train['power_consumption'] == 0].tolist()\n",
        "print(f\"제거할 이상치 개수: {len(outlier_idx)}\")\n",
        "train.drop(index=outlier_idx, inplace=True)\n",
        "print(f\"남은 행 개수: {train.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "�� Z-score 방법으로 이상치 탐지 (임계값: 4.5)\n",
            "============================================================\n",
            "📊 발견된 이상치: 68개\n",
            "�� 이상치가 있는 건물 수: 11개\n",
            "🏢 이상치가 있는 건물 번호: [23, 30, 41, 43, 52, 64, 67, 72, 76, 81, 99]\n",
            "\n",
            "📈 건물별 이상치 개수:\n",
            "   건물 67 (IDC): 48개\n",
            "   건물 41 (Commercial): 4개\n",
            "   건물 43 (IDC): 4개\n",
            "   건물 30 (IDC): 2개\n",
            "   건물 52 (IDC): 2개\n",
            "   건물 76 (Commercial): 2개\n",
            "   건물 99 (Commercial): 2개\n",
            "   건물 23 (Research Institute): 1개\n",
            "   건물 64 (IDC): 1개\n",
            "   건물 72 (Public): 1개\n",
            "   건물 81 (IDC): 1개\n",
            "\n",
            "📊 이상치 상세 분석:\n",
            "============================================================\n",
            "\n",
            "🏢 건물 23 (Research Institute):\n",
            "   이상치 개수: 1개\n",
            "   최소 전력소비량: 9324.00 kWh\n",
            "   최대 전력소비량: 9324.00 kWh\n",
            "   평균 전력소비량: 9324.00 kWh\n",
            "   전체 데이터 평균: 2339.77 kWh\n",
            "   이상치 비율: 0.05%\n",
            "\n",
            "🏢 건물 30 (IDC):\n",
            "   이상치 개수: 2개\n",
            "   최소 전력소비량: 2444.40 kWh\n",
            "   최대 전력소비량: 7374.24 kWh\n",
            "   평균 전력소비량: 4909.32 kWh\n",
            "   전체 데이터 평균: 9801.04 kWh\n",
            "   이상치 비율: 0.10%\n",
            "\n",
            "🏢 건물 41 (Commercial):\n",
            "   이상치 개수: 4개\n",
            "   최소 전력소비량: 246.24 kWh\n",
            "   최대 전력소비량: 2102.94 kWh\n",
            "   평균 전력소비량: 1373.76 kWh\n",
            "   전체 데이터 평균: 2710.89 kWh\n",
            "   이상치 비율: 0.20%\n",
            "\n",
            "🏢 건물 43 (IDC):\n",
            "   이상치 개수: 4개\n",
            "   최소 전력소비량: 834.60 kWh\n",
            "   최대 전력소비량: 9765.60 kWh\n",
            "   평균 전력소비량: 5587.50 kWh\n",
            "   전체 데이터 평균: 14058.80 kWh\n",
            "   이상치 비율: 0.20%\n",
            "\n",
            "🏢 건물 52 (IDC):\n",
            "   이상치 개수: 2개\n",
            "   최소 전력소비량: 1437.84 kWh\n",
            "   최대 전력소비량: 2605.68 kWh\n",
            "   평균 전력소비량: 2021.76 kWh\n",
            "   전체 데이터 평균: 5099.60 kWh\n",
            "   이상치 비율: 0.10%\n",
            "\n",
            "🏢 건물 64 (IDC):\n",
            "   이상치 개수: 1개\n",
            "   최소 전력소비량: 13615.92 kWh\n",
            "   최대 전력소비량: 13615.92 kWh\n",
            "   평균 전력소비량: 13615.92 kWh\n",
            "   전체 데이터 평균: 11002.92 kWh\n",
            "   이상치 비율: 0.05%\n",
            "\n",
            "🏢 건물 67 (IDC):\n",
            "   이상치 개수: 48개\n",
            "   최소 전력소비량: 60.30 kWh\n",
            "   최대 전력소비량: 6263.10 kWh\n",
            "   평균 전력소비량: 5541.75 kWh\n",
            "   전체 데이터 평균: 10722.11 kWh\n",
            "   이상치 비율: 2.35%\n",
            "\n",
            "🏢 건물 72 (Public):\n",
            "   이상치 개수: 1개\n",
            "   최소 전력소비량: 39.00 kWh\n",
            "   최대 전력소비량: 39.00 kWh\n",
            "   평균 전력소비량: 39.00 kWh\n",
            "   전체 데이터 평균: 1395.94 kWh\n",
            "   이상치 비율: 0.05%\n",
            "\n",
            "🏢 건물 76 (Commercial):\n",
            "   이상치 개수: 2개\n",
            "   최소 전력소비량: 1406.16 kWh\n",
            "   최대 전력소비량: 1595.52 kWh\n",
            "   평균 전력소비량: 1500.84 kWh\n",
            "   전체 데이터 평균: 3120.70 kWh\n",
            "   이상치 비율: 0.10%\n",
            "\n",
            "🏢 건물 81 (IDC):\n",
            "   이상치 개수: 1개\n",
            "   최소 전력소비량: 650.64 kWh\n",
            "   최대 전력소비량: 650.64 kWh\n",
            "   평균 전력소비량: 650.64 kWh\n",
            "   전체 데이터 평균: 1223.75 kWh\n",
            "   이상치 비율: 0.05%\n",
            "\n",
            "🏢 건물 99 (Commercial):\n",
            "   이상치 개수: 2개\n",
            "   최소 전력소비량: 370.80 kWh\n",
            "   최대 전력소비량: 380.88 kWh\n",
            "   평균 전력소비량: 375.84 kWh\n",
            "   전체 데이터 평균: 1072.62 kWh\n",
            "   이상치 비율: 0.10%\n"
          ]
        }
      ],
      "source": [
        "# 이상치 제거 (Z-score 기반 )\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def detect_outliers_zscore_only(train, threshold=4.5):\n",
        "    \"\"\"\n",
        "    Z-score 방법으로만 이상치를 찾아내는 함수\n",
        "    \n",
        "    Args:\n",
        "        train (pd.DataFrame): 전처리된 전체 학습 데이터\n",
        "        threshold (float): Z-score 임계값 (기본값: 3)\n",
        "    \n",
        "    Returns:\n",
        "        pd.DataFrame: 이상치 데이터\n",
        "    \"\"\"\n",
        "    print(f\"�� Z-score 방법으로 이상치 탐지 (임계값: {threshold})\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    outliers_list = []\n",
        "    \n",
        "    for building_num in train['building_number'].unique():\n",
        "        building_data = train[train['building_number'] == building_num]['power_consumption']\n",
        "        \n",
        "        # Z-score 계산\n",
        "        z_scores = np.abs(stats.zscore(building_data))\n",
        "        \n",
        "        # 임계값을 초과하는 이상치 찾기\n",
        "        building_outliers = train[(train['building_number'] == building_num) & \n",
        "                                          (z_scores > threshold)]\n",
        "        \n",
        "        if not building_outliers.empty:\n",
        "            outliers_list.append(building_outliers)\n",
        "    \n",
        "    outliers_df = pd.concat(outliers_list) if outliers_list else pd.DataFrame()\n",
        "    \n",
        "    print(f\"📊 발견된 이상치: {len(outliers_df)}개\")\n",
        "    \n",
        "    if not outliers_df.empty:\n",
        "        print(f\"�� 이상치가 있는 건물 수: {outliers_df['building_number'].nunique()}개\")\n",
        "        print(f\"🏢 이상치가 있는 건물 번호: {sorted(outliers_df['building_number'].unique())}\")\n",
        "        \n",
        "        # 건물별 이상치 개수\n",
        "        building_counts = outliers_df['building_number'].value_counts()\n",
        "        print(f\"\\n📈 건물별 이상치 개수:\")\n",
        "        for building_num, count in building_counts.items():\n",
        "            building_type = building_info[building_info['building_number'] == building_num]['building_type'].iloc[0]\n",
        "            print(f\"   건물 {building_num} ({building_type}): {count}개\")\n",
        "    else:\n",
        "        print(\"✅ 이상치가 발견되지 않았습니다.\")\n",
        "    \n",
        "    return outliers_df\n",
        "\n",
        "# Z-score 이상치 탐지 실행\n",
        "outliers_df = detect_outliers_zscore_only(train, threshold=4.5)\n",
        "\n",
        "# 이상치 상세 분석\n",
        "if not outliers_df.empty:\n",
        "    print(f\"\\n📊 이상치 상세 분석:\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for building_num in sorted(outliers_df['building_number'].unique()):\n",
        "        building_outliers = outliers_df[outliers_df['building_number'] == building_num]\n",
        "        building_type = building_info[building_info['building_number'] == building_num]['building_type'].iloc[0]\n",
        "        \n",
        "        print(f\"\\n🏢 건물 {building_num} ({building_type}):\")\n",
        "        print(f\"   이상치 개수: {len(building_outliers)}개\")\n",
        "        print(f\"   최소 전력소비량: {building_outliers['power_consumption'].min():.2f} kWh\")\n",
        "        print(f\"   최대 전력소비량: {building_outliers['power_consumption'].max():.2f} kWh\")\n",
        "        print(f\"   평균 전력소비량: {building_outliers['power_consumption'].mean():.2f} kWh\")\n",
        "        \n",
        "        # 전체 건물 데이터와 비교\n",
        "        building_all = train[train['building_number'] == building_num]\n",
        "        print(f\"   전체 데이터 평균: {building_all['power_consumption'].mean():.2f} kWh\")\n",
        "        print(f\"   이상치 비율: {len(building_outliers)/len(building_all)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 안전한 이상치 제거 시작\n",
            "   원본 데이터 크기: 203932개\n",
            "   제거할 이상치 개수: 68개\n",
            "   제거 후 데이터 크기: 203864개\n",
            "   실제 제거된 행 수: 68개\n",
            "   제거된 데이터 비율: 0.03%\n",
            "\n",
            "📊 안전한 이상치 제거 결과:\n",
            "   확인: 203864개\n",
            "\n",
            "✅ train 변수에 정제된 데이터가 저장되었습니다.\n"
          ]
        }
      ],
      "source": [
        "def drop_outliers_safe(train, outliers_df):\n",
        "    \"\"\"\n",
        "    안전한 방법으로 이상치 제거 (모든 컬럼 매칭)\n",
        "    \n",
        "    Args:\n",
        "        train (pd.DataFrame): 전체 학습 데이터\n",
        "        outliers_df (pd.DataFrame): 이상치 데이터\n",
        "    \n",
        "    Returns:\n",
        "        pd.DataFrame: 이상치가 제거된 데이터\n",
        "    \"\"\"\n",
        "    print(f\"🔍 안전한 이상치 제거 시작\")\n",
        "    print(f\"   원본 데이터 크기: {len(train)}개\")\n",
        "    print(f\"   제거할 이상치 개수: {len(outliers_df)}개\")\n",
        "    \n",
        "    # 정제된 데이터 초기화\n",
        "    cleaned_data = train.copy()\n",
        "    \n",
        "    # 이상치가 있는 건물들만 처리\n",
        "    outlier_buildings = outliers_df['building_number'].unique()\n",
        "    \n",
        "    removed_count = 0\n",
        "    for building_num in outlier_buildings:\n",
        "        building_outliers = outliers_df[outliers_df['building_number'] == building_num]\n",
        "        \n",
        "        # 해당 건물의 데이터에서 이상치 제거\n",
        "        building_mask = cleaned_data['building_number'] == building_num\n",
        "        \n",
        "        for _, outlier_row in building_outliers.iterrows():\n",
        "            # 정확히 일치하는 행 찾기\n",
        "            match_mask = (\n",
        "                (cleaned_data['building_number'] == outlier_row['building_number']) &\n",
        "                (cleaned_data['date_time'] == outlier_row['date_time']) &\n",
        "                (cleaned_data['power_consumption'] == outlier_row['power_consumption'])\n",
        "            )\n",
        "            \n",
        "            # 일치하는 행 제거\n",
        "            cleaned_data = cleaned_data[~match_mask]\n",
        "            removed_count += match_mask.sum()\n",
        "    \n",
        "    print(f\"   제거 후 데이터 크기: {len(cleaned_data)}개\")\n",
        "    print(f\"   실제 제거된 행 수: {removed_count}개\")\n",
        "    print(f\"   제거된 데이터 비율: {removed_count/len(train)*100:.2f}%\")\n",
        "    \n",
        "    return cleaned_data\n",
        "\n",
        "# 안전한 이상치 제거 실행\n",
        "train = drop_outliers_safe(train, outliers_df)\n",
        "\n",
        "# 결과 확인\n",
        "print(f\"\\n📊 안전한 이상치 제거 결과:\")\n",
        "print(f\"   확인: {len(train)}개\")\n",
        "\n",
        "# 정제된 데이터를 새로운 변수에 저장\n",
        "print(f\"\\n✅ train 변수에 정제된 데이터가 저장되었습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 공휴일(holiday), 주말(weekend), 닫은날(close)로 세분화# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. 기본 공휴일 및 주말 피처 생성\n",
        "holi_weekday = ['2024-06-06', '2024-08-15']  # 공휴일 목록\n",
        "for df in [train, test]:\n",
        "    # 공휴일 (국가 공휴일)\n",
        "    df['holiday'] = np.where(\n",
        "        df.date_time.dt.strftime('%Y-%m-%d').isin(holi_weekday), 1, 0\n",
        "    )\n",
        "    \n",
        "    # 주말 (토요일, 일요일)\n",
        "    df['weekend'] = np.where(\n",
        "        df.day_of_week >= 5, 1, 0\n",
        "    )\n",
        "    \n",
        "    # 닫은날 (초기값 0으로 설정, 나중에 건물별 규칙 적용)\n",
        "    df['close'] = 0\n",
        "\n",
        "\n",
        "# 주기성 피처 생성 (Cyclical Features)\n",
        "for df in [train, test]:\n",
        "    # 시간 주기성\n",
        "    df['sin_hour'] = np.sin(2 * np.pi * df['hour'] / 23.0)\n",
        "    df['cos_hour'] = np.cos(2 * np.pi * df['hour'] / 23.0)\n",
        "    \n",
        "    # 날짜 주기성\n",
        "    df['sin_date'] = -np.sin(2 * np.pi * (df['month'] + df['day'] / 31) / 12)\n",
        "    df['cos_date'] = -np.cos(2 * np.pi * (df['month'] + df['day'] / 31) / 12)\n",
        "    \n",
        "    # 월 주기성\n",
        "    df['sin_month'] = -np.sin(2 * np.pi * df['month'] / 12.0)\n",
        "    df['cos_month'] = -np.cos(2 * np.pi * df['month'] / 12.0)\n",
        "    \n",
        "    # 요일 주기성\n",
        "    df['sin_dayofweek'] = -np.sin(2 * np.pi * (df['day_of_week'] + 1) / 7.0)\n",
        "    df['cos_dayofweek'] = -np.cos(2 * np.pi * (df['day_of_week'] + 1) / 7.0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_specific_building_holidays(df):\n",
        "    \"\"\"\n",
        "    특정 건물들의 휴일 규칙을 적용하는 함수\n",
        "    - 18번 건물: 매주 일요일 휴무 (close)\n",
        "    - 27, 40, 59, 63번 건물: 홀수 주 일요일 휴무 (close)\n",
        "    - 29번 건물: 매달 10일 + 5번째 주 일요일 휴무 (close)\n",
        "    - 32번 건물: 홀수 주 월요일 휴무 (close)\n",
        "    \"\"\"\n",
        "    print(\"🔧 특정 건물 휴일 규칙 적용 중... (달력 기준 주차)\")\n",
        "    department_store_buildings = building_info[building_info['building_type'] == 'Department Store']['building_number'].tolist()\n",
        "\n",
        "    # 매주 일요일 휴무 건물 (18번)\n",
        "    every_sunday_buildings = [18]\n",
        "\n",
        "    # 홀수 주 일요일 휴무 건물들 (27, 40, 59, 63)\n",
        "    odd_week_sunday_buildings = [27, 40, 59, 63]\n",
        "\n",
        "    # 매달 10일 + 5번째 주 일요일 휴무 건물 (29)\n",
        "    special_holiday_building = [29]\n",
        "\n",
        "    # 홀수 주 월요일 휴무 건물 (32)\n",
        "    odd_week_monday_buildings = [32]\n",
        "\n",
        "    # 달력 기준 주차 계산 (일요일 시작)\n",
        "    def get_calendar_week_of_month(date_series):\n",
        "        \"\"\"달력 기준 주차 계산 (월의 첫날이 포함된 주를 1주차로)\"\"\"\n",
        "        result = []\n",
        "        for date in date_series:\n",
        "            first_day = date.replace(day=1)\n",
        "            first_day_weekday = first_day.weekday()\n",
        "            days_to_week_start = (first_day_weekday + 1) % 7  # 일요일 기준\n",
        "            week_start_of_first = first_day - pd.Timedelta(days=days_to_week_start)\n",
        "            days_since_first_week_start = (date - week_start_of_first).days\n",
        "            week_num = (days_since_first_week_start // 7) + 1\n",
        "            result.append(week_num)\n",
        "        return result\n",
        "\n",
        "    # 달력 기준 주차 계산\n",
        "    df['calendar_week_of_month'] = get_calendar_week_of_month(df['date_time'])\n",
        "\n",
        "    # 0. 매주 일요일 휴무 (18번 건물) - close에 적용\n",
        "    for building_num in every_sunday_buildings:\n",
        "        mask = (df['building_number'] == building_num) & (df['day_of_week'] == 6)\n",
        "        df.loc[mask, 'close'] = 1\n",
        "        count = mask.sum()\n",
        "        print(f\"   건물 {building_num}: 매주 일요일 휴일 {count}개 적용\")\n",
        "\n",
        "    # 1. 홀수 주 일요일 휴무 (27, 40, 59, 63번 건물) - close에 적용\n",
        "    for building_num in odd_week_sunday_buildings:\n",
        "        mask = (df['building_number'] == building_num) & \\\n",
        "               (df['day_of_week'] == 6) & \\\n",
        "               (df['calendar_week_of_month'] % 2 == 1)\n",
        "        df.loc[mask, 'close'] = 1\n",
        "        count = mask.sum()\n",
        "        print(f\"   건물 {building_num}: 홀수 주 일요일 휴일 {count}개 적용\")\n",
        "\n",
        "    # 2. 매달 10일 + 5번째 주 일요일 휴무 (29번 건물) - close에 적용\n",
        "    for building_num in special_holiday_building:\n",
        "        mask_10th = (df['building_number'] == building_num) & (df['date_time'].dt.day == 10)\n",
        "        df.loc[mask_10th, 'close'] = 1\n",
        "        count_10th = mask_10th.sum()\n",
        "        mask_5th_sunday = (df['building_number'] == building_num) & \\\n",
        "                          (df['day_of_week'] == 6) & \\\n",
        "                          (df['calendar_week_of_month'] == 5)\n",
        "        df.loc[mask_5th_sunday, 'close'] = 1\n",
        "        count_5th_sunday = mask_5th_sunday.sum()\n",
        "        print(f\"   건물 {building_num}: 매달 10일 휴일 {count_10th}개, 5번째 주 일요일 {count_5th_sunday}개 적용\")\n",
        "\n",
        "    # 3. 홀수 주 월요일 휴무 (32번 건물) - close에 적용\n",
        "    for building_num in odd_week_monday_buildings:\n",
        "        mask = (df['building_number'] == building_num) & \\\n",
        "               (df['day_of_week'] == 0) & \\\n",
        "               (df['calendar_week_of_month'] % 2 == 1)\n",
        "        df.loc[mask, 'close'] = 1\n",
        "        count = mask.sum()\n",
        "        print(f\"   건물 {building_num}: 홀수 주 월요일 휴일 {count}개 적용\")\n",
        "\n",
        "    # 임시 컬럼 제거\n",
        "    df.drop(['calendar_week_of_month'], axis=1, inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def create_inferred_holidays(df, building_info):\n",
        "    # 규칙이 없는 백화점 건물 번호 추출\n",
        "    department_store_buildings = [19,34,45,54,73,74,79,88,95]\n",
        "\n",
        "    # 백화점 건물에 대해 추정 휴일만 적용\n",
        "    for building_num in department_store_buildings:\n",
        "        building_data = df[df['building_number'] == building_num].copy()\n",
        "\n",
        "        if len(building_data) > 0:\n",
        "            # 일별 전력소비량 계산\n",
        "            building_data['date'] = building_data['date_time'].dt.date\n",
        "            daily_consumption = building_data.groupby('date')['power_consumption'].sum()\n",
        "\n",
        "            # 전체 평균 기준 임계치 (0.7배)\n",
        "            threshold = daily_consumption.mean() * 0.7\n",
        "            inferred_holiday_dates = daily_consumption[daily_consumption < threshold].index\n",
        "\n",
        "            # 추정 휴일을 해당 건물의 holiday 컬럼에 적용\n",
        "            for holiday_date in inferred_holiday_dates:\n",
        "                mask = (df['building_number'] == building_num) & (df['date_time'].dt.date == holiday_date)\n",
        "                df.loc[mask, 'close'] = 1\n",
        "\n",
        "    return df\n",
        "\n",
        "# 휴일 피처 생성\n",
        "train = create_inferred_holidays(train, building_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 특정 건물 휴일 규칙 적용 중... (달력 기준 주차)\n",
            "   건물 18: 매주 일요일 휴일 288개 적용\n",
            "   건물 27: 홀수 주 일요일 휴일 120개 적용\n",
            "   건물 40: 홀수 주 일요일 휴일 120개 적용\n",
            "   건물 59: 홀수 주 일요일 휴일 120개 적용\n",
            "   건물 63: 홀수 주 일요일 휴일 120개 적용\n",
            "   건물 29: 매달 10일 휴일 72개, 5번째 주 일요일 48개 적용\n",
            "   건물 32: 홀수 주 월요일 휴일 144개 적용\n",
            "🔧 특정 건물 휴일 규칙 적용 중... (달력 기준 주차)\n",
            "   건물 18: 매주 일요일 휴일 24개 적용\n",
            "   건물 27: 홀수 주 일요일 휴일 24개 적용\n",
            "   건물 40: 홀수 주 일요일 휴일 24개 적용\n",
            "   건물 59: 홀수 주 일요일 휴일 24개 적용\n",
            "   건물 63: 홀수 주 일요일 휴일 24개 적용\n",
            "   건물 29: 매달 10일 휴일 0개, 5번째 주 일요일 24개 적용\n",
            "   건물 32: 홀수 주 월요일 휴일 24개 적용\n"
          ]
        }
      ],
      "source": [
        "train = apply_specific_building_holidays(train)\n",
        "test = apply_specific_building_holidays(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 특정 건물들과 학교/병원/연구소 건물들을 주말/공휴일에 close 처리 중...\n",
            "📋 대상 건물 수: 41개\n",
            "   특정 건물: [6, 16, 20, 51, 86, 47, 69, 38, 50, 66, 68, 72, 80]\n",
            "   학교/병원/연구소: [3, 5, 8, 12, 13, 14, 15, 17, 21, 22, 23, 24, 37, 39, 42, 44, 46, 48, 49, 53, 55, 60, 62, 75, 83, 87, 90, 94]\n",
            "   건물 6 (Commercial): 648개 close 처리\n",
            "   건물 16 (Commercial): 648개 close 처리\n",
            "   건물 20 (Commercial): 648개 close 처리\n",
            "   건물 51 (Commercial): 648개 close 처리\n",
            "   건물 86 (Commercial): 648개 close 처리\n",
            "   건물 47 (Other Buildings): 648개 close 처리\n",
            "   건물 69 (Other Buildings): 648개 close 처리\n",
            "   건물 38 (Public): 648개 close 처리\n",
            "   건물 50 (Public): 648개 close 처리\n",
            "   건물 66 (Public): 648개 close 처리\n",
            "   건물 68 (Public): 647개 close 처리\n",
            "   건물 72 (Public): 646개 close 처리\n",
            "   건물 80 (Public): 648개 close 처리\n",
            "   건물 3 (Hospital): 648개 close 처리\n",
            "   건물 5 (University): 648개 close 처리\n",
            "   건물 8 (University): 645개 close 처리\n",
            "   건물 12 (University): 648개 close 처리\n",
            "   건물 13 (Research Institute): 648개 close 처리\n",
            "   건물 14 (University): 648개 close 처리\n",
            "   건물 15 (Research Institute): 648개 close 처리\n",
            "   건물 17 (Hospital): 648개 close 처리\n",
            "   건물 21 (Hospital): 648개 close 처리\n",
            "   건물 22 (University): 648개 close 처리\n",
            "   건물 23 (Research Institute): 648개 close 처리\n",
            "   건물 24 (University): 648개 close 처리\n",
            "   건물 37 (Research Institute): 648개 close 처리\n",
            "   건물 39 (Hospital): 648개 close 처리\n",
            "   건물 42 (Hospital): 648개 close 처리\n",
            "   건물 44 (Hospital): 647개 close 처리\n",
            "   건물 46 (University): 648개 close 처리\n",
            "   건물 48 (Hospital): 648개 close 처리\n",
            "   건물 49 (Research Institute): 648개 close 처리\n",
            "   건물 53 (Research Institute): 646개 close 처리\n",
            "   건물 55 (University): 648개 close 처리\n",
            "   건물 60 (University): 648개 close 처리\n",
            "   건물 62 (Research Institute): 648개 close 처리\n",
            "   건물 75 (Hospital): 648개 close 처리\n",
            "   건물 83 (Research Institute): 648개 close 처리\n",
            "   건물 87 (University): 648개 close 처리\n",
            "   건물 90 (Hospital): 648개 close 처리\n",
            "   건물 94 (Research Institute): 646개 close 처리\n",
            "\\n�� 전체 close 처리 결과:\n",
            "   총 close 건수: 27973개\n",
            "🔧 특정 건물들과 학교/병원/연구소 건물들을 주말/공휴일에 close 처리 중...\n",
            "📋 대상 건물 수: 41개\n",
            "   특정 건물: [6, 16, 20, 51, 86, 47, 69, 38, 50, 66, 68, 72, 80]\n",
            "   학교/병원/연구소: [3, 5, 8, 12, 13, 14, 15, 17, 21, 22, 23, 24, 37, 39, 42, 44, 46, 48, 49, 53, 55, 60, 62, 75, 83, 87, 90, 94]\n",
            "   건물 6 (Commercial): 48개 close 처리\n",
            "   건물 16 (Commercial): 48개 close 처리\n",
            "   건물 20 (Commercial): 48개 close 처리\n",
            "   건물 51 (Commercial): 48개 close 처리\n",
            "   건물 86 (Commercial): 48개 close 처리\n",
            "   건물 47 (Other Buildings): 48개 close 처리\n",
            "   건물 69 (Other Buildings): 48개 close 처리\n",
            "   건물 38 (Public): 48개 close 처리\n",
            "   건물 50 (Public): 48개 close 처리\n",
            "   건물 66 (Public): 48개 close 처리\n",
            "   건물 68 (Public): 48개 close 처리\n",
            "   건물 72 (Public): 48개 close 처리\n",
            "   건물 80 (Public): 48개 close 처리\n",
            "   건물 3 (Hospital): 48개 close 처리\n",
            "   건물 5 (University): 48개 close 처리\n",
            "   건물 8 (University): 48개 close 처리\n",
            "   건물 12 (University): 48개 close 처리\n",
            "   건물 13 (Research Institute): 48개 close 처리\n",
            "   건물 14 (University): 48개 close 처리\n",
            "   건물 15 (Research Institute): 48개 close 처리\n",
            "   건물 17 (Hospital): 48개 close 처리\n",
            "   건물 21 (Hospital): 48개 close 처리\n",
            "   건물 22 (University): 48개 close 처리\n",
            "   건물 23 (Research Institute): 48개 close 처리\n",
            "   건물 24 (University): 48개 close 처리\n",
            "   건물 37 (Research Institute): 48개 close 처리\n",
            "   건물 39 (Hospital): 48개 close 처리\n",
            "   건물 42 (Hospital): 48개 close 처리\n",
            "   건물 44 (Hospital): 48개 close 처리\n",
            "   건물 46 (University): 48개 close 처리\n",
            "   건물 48 (Hospital): 48개 close 처리\n",
            "   건물 49 (Research Institute): 48개 close 처리\n",
            "   건물 53 (Research Institute): 48개 close 처리\n",
            "   건물 55 (University): 48개 close 처리\n",
            "   건물 60 (University): 48개 close 처리\n",
            "   건물 62 (Research Institute): 48개 close 처리\n",
            "   건물 75 (Hospital): 48개 close 처리\n",
            "   건물 83 (Research Institute): 48개 close 처리\n",
            "   건물 87 (University): 48개 close 처리\n",
            "   건물 90 (Hospital): 48개 close 처리\n",
            "   건물 94 (Research Institute): 48개 close 처리\n",
            "\\n�� 전체 close 처리 결과:\n",
            "   총 close 건수: 2136개\n",
            "✅ 특정 건물들과 학교/병원/연구소 건물들의 주말/공휴일 close 처리 완료\n"
          ]
        }
      ],
      "source": [
        "# 특정 건물들과 학교/병원/연구소 건물들을 주말/공휴일에 close 처리하는 함수\n",
        "def apply_weekend_holiday_close_for_specific_buildings(df, building_info):\n",
        "    \"\"\"\n",
        "    특정 건물들과 학교/병원/연구소 건물들을 주말과 공휴일에 close 처리\n",
        "    \n",
        "    Args:\n",
        "        df: train 또는 test 데이터프레임\n",
        "        building_info: 건물 정보 데이터프레임\n",
        "    \n",
        "    Returns:\n",
        "        df: close 피처가 업데이트된 데이터프레임\n",
        "    \"\"\"\n",
        "    print(\"🔧 특정 건물들과 학교/병원/연구소 건물들을 주말/공휴일에 close 처리 중...\")\n",
        "    \n",
        "    # 특정 건물 번호 리스트\n",
        "    specific_buildings = [6, 16, 20, 51, 86, 47, 69, 38, 50, 66, 68, 72, 80]\n",
        "    \n",
        "    # 학교, 병원, 연구소 건물 번호 추출\n",
        "    school_hospital_research_buildings = building_info[\n",
        "        building_info['building_type'].isin(['University', 'Hospital', 'Research Institute'])\n",
        "    ]['building_number'].tolist()\n",
        "    \n",
        "    # 모든 대상 건물 번호\n",
        "    target_buildings = specific_buildings + school_hospital_research_buildings\n",
        "    \n",
        "    print(f\"📋 대상 건물 수: {len(target_buildings)}개\")\n",
        "    print(f\"   특정 건물: {specific_buildings}\")\n",
        "    print(f\"   학교/병원/연구소: {school_hospital_research_buildings}\")\n",
        "    \n",
        "    # 주말 또는 공휴일인 경우 close = 1로 설정\n",
        "    for building_num in target_buildings:\n",
        "        # 해당 건물의 데이터에서 주말 또는 공휴일인 경우\n",
        "        mask = (df['building_number'] == building_num) & \\\n",
        "               ((df['weekend'] == 1) | (df['holiday'] == 1))\n",
        "        \n",
        "        # close 피처를 1로 설정\n",
        "        df.loc[mask, 'close'] = 1\n",
        "        \n",
        "        # 적용된 건수 확인\n",
        "        applied_count = mask.sum()\n",
        "        if applied_count > 0:\n",
        "            building_type = building_info[building_info['building_number'] == building_num]['building_type'].iloc[0]\n",
        "            print(f\"   건물 {building_num} ({building_type}): {applied_count}개 close 처리\")\n",
        "    \n",
        "    # 전체 적용 결과 확인\n",
        "    total_close_count = df[df['close'] == 1].shape[0]\n",
        "    print(f\"\\\\n�� 전체 close 처리 결과:\")\n",
        "    print(f\"   총 close 건수: {total_close_count}개\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "# 함수 실행\n",
        "train = apply_weekend_holiday_close_for_specific_buildings(train, building_info)\n",
        "test = apply_weekend_holiday_close_for_specific_buildings(test, building_info)\n",
        "\n",
        "print(\"✅ 특정 건물들과 학교/병원/연구소 건물들의 주말/공휴일 close 처리 완료\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 휴일 적용 확인용 \n",
        "def check_holiday(n,option='holiday'):\n",
        "    if option == 'holiday':\n",
        "        holiday_dates_n = train.loc[(train['building_number'] == n) & (train['holiday'] == 1), 'date_time'].dt.date\n",
        "        unique_holiday_dates_n = holiday_dates_n.drop_duplicates().tolist()\n",
        "        print(\"train 데이터 휴일 확인\")\n",
        "        print(f\"건물 {n}번  휴일: {len(unique_holiday_dates_n)}일\")\n",
        "        print(f\"날짜: {unique_holiday_dates_n[:10]}...\")  # 처음 10개만 출력\n",
        "        holiday_dates_n = test.loc[(test['building_number'] == n) & (test['holiday'] == 1), 'date_time'].dt.date\n",
        "        unique_holiday_dates_n = holiday_dates_n.drop_duplicates().tolist()\n",
        "        print(\"test 데이터 휴일 확인\")\n",
        "        print(f\"건물 {n}번  휴일: {len(unique_holiday_dates_n)}일\")\n",
        "        print(f\"날짜: {unique_holiday_dates_n[:10]}...\")  # 처음 10개만 출력        \n",
        "    if option == 'weekend':\n",
        "        weekend_dates_n = train.loc[(train['building_number'] == n) & (train['weekend'] == 1), 'date_time'].dt.date\n",
        "        unique_weekend_dates_n = weekend_dates_n.drop_duplicates().tolist()\n",
        "        print(\"train 데이터 주말 확인\")\n",
        "        print(f\"건물 {n}번  주말: {len(unique_weekend_dates_n)}일\")\n",
        "        print(f\"날짜: {unique_weekend_dates_n[:10]}...\")  # 처음 10개만 출력\n",
        "        weekend_dates_n = test.loc[(test['building_number'] == n) & (test['weekend'] == 1), 'date_time'].dt.date\n",
        "        unique_weekend_dates_n = weekend_dates_n.drop_duplicates().tolist()\n",
        "        print(\"test 데이터 주말 확인\")\n",
        "        print(f\"건물 {n}번  주말: {len(unique_weekend_dates_n)}일\")\n",
        "        print(f\"날짜: {unique_weekend_dates_n[:10]}...\")  # 처음 10개만 출력\n",
        "    if option == 'close':\n",
        "        close_dates_n = train.loc[(train['building_number'] == n) & (train['close'] == 1), 'date_time'].dt.date\n",
        "        unique_close_dates_n = close_dates_n.drop_duplicates().tolist()\n",
        "        print(\"train 데이터 닫은날 확인\")\n",
        "        print(f\"건물 {n}번  닫은날: {len(unique_close_dates_n)}일\")\n",
        "        print(f\"날짜: {unique_close_dates_n[:10]}...\")  # 처음 10개만 출력\n",
        "        close_dates_n = test.loc[(test['building_number'] == n) & (test['close'] == 1), 'date_time'].dt.date\n",
        "        unique_close_dates_n = close_dates_n.drop_duplicates().tolist()\n",
        "        print(\"test 데이터 닫은날 확인\")\n",
        "        print(f\"건물 {n}번  닫은날: {len(unique_close_dates_n)}일\")\n",
        "        print(f\"날짜: {unique_close_dates_n[:10]}...\")  # 처음 10개만 출력\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train 데이터 닫은날 확인\n",
            "건물 19번  닫은날: 3일\n",
            "날짜: [datetime.date(2024, 6, 10), datetime.date(2024, 7, 8), datetime.date(2024, 8, 19)]...\n",
            "test 데이터 닫은날 확인\n",
            "건물 19번  닫은날: 0일\n",
            "날짜: []...\n"
          ]
        }
      ],
      "source": [
        "check_holiday(19,'close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 기상 관련 파생 피처 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# 기상 관련 파생 피처 생성\n",
        "def CDH(xs):\n",
        "    \"\"\"Cooling Degree Hours 계산\"\"\"\n",
        "    cumsum = np.cumsum(xs - 26)\n",
        "    return np.concatenate((cumsum[:11], cumsum[11:] - cumsum[:-11]))\n",
        "\n",
        "def calculate_and_add_cdh(dataframe):\n",
        "    \"\"\"건물별 CDH 계산 및 추가\"\"\"\n",
        "    cdhs = []\n",
        "    for i in range(1, 101):\n",
        "        temp = dataframe[dataframe['building_number'] == i]['temperature'].values\n",
        "        cdh = CDH(temp)\n",
        "        cdhs.append(cdh)\n",
        "    return np.concatenate(cdhs)\n",
        "\n",
        "# CDH, THI, WCT 피처 생성\n",
        "train['CDH'] = calculate_and_add_cdh(train)\n",
        "test['CDH'] = calculate_and_add_cdh(test)\n",
        "\n",
        "# THI (Temperature Humidity Index)\n",
        "train['THI'] = 9/5 * train['temperature'] - 0.55 * (1 - train['humidity']/100) * (9/5 * train['temperature'] - 26) + 32\n",
        "test['THI'] = 9/5 * test['temperature'] - 0.55 * (1 - test['humidity']/100) * (9/5 * test['temperature'] - 26) + 32\n",
        "\n",
        "# WCT (Wind Chill Temperature)\n",
        "train['WCT'] = 13.12 + 0.6125 * train['temperature'] - 11.37 * (train['windspeed']**0.16) + 0.3965 * (train['windspeed']**0.16) * train['temperature']\n",
        "test['WCT'] = 13.12 + 0.6125 * test['temperature'] - 11.37 * (test['windspeed']**0.16) + 0.3965 * (test['windspeed']**0.16) * test['temperature']\n",
        "\n",
        "print(\"✅ 기상 관련 파생 피처 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 전력 소비량 기반 통계 피처 생성 중...\n",
            "✅ 전력 소비량 기반 통계 피처 생성 완료\n",
            "최종 train 데이터 shape: (203864, 43)\n",
            "최종 test 데이터 shape: (16800, 40)\n"
          ]
        }
      ],
      "source": [
        "# 전력 소비량 기반 통계 피처 생성 (Target-like Features)\n",
        "print(\"📊 전력 소비량 기반 통계 피처 생성 중...\")\n",
        "\n",
        "# 건물별 시간대/요일별 평균 및 표준편차\n",
        "power_mean = pd.pivot_table(train, values='power_consumption', \n",
        "                           index=['building_number', 'hour', 'day_of_week'], \n",
        "                           aggfunc=np.mean).reset_index()\n",
        "power_mean.columns = ['building_number', 'hour', 'day_of_week', 'day_hour_mean']\n",
        "\n",
        "power_std = pd.pivot_table(train, values='power_consumption', \n",
        "                          index=['building_number', 'hour', 'day_of_week'], \n",
        "                          aggfunc=np.std).reset_index()\n",
        "power_std.columns = ['building_number', 'hour', 'day_of_week', 'day_hour_std']\n",
        "\n",
        "# 건물별 시간대별 평균 및 표준편차\n",
        "power_hour_mean = pd.pivot_table(train, values='power_consumption', \n",
        "                                index=['building_number', 'hour'], \n",
        "                                aggfunc=np.mean).reset_index()\n",
        "power_hour_mean.columns = ['building_number', 'hour', 'hour_mean']\n",
        "\n",
        "power_hour_std = pd.pivot_table(train, values='power_consumption', \n",
        "                               index=['building_number', 'hour'], \n",
        "                               aggfunc=np.std).reset_index()\n",
        "power_hour_std.columns = ['building_number', 'hour', 'hour_std']\n",
        "\n",
        "# 통계 피처 병합\n",
        "train = train.merge(power_mean, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
        "train = train.merge(power_std, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
        "train = train.merge(power_hour_mean, on=['building_number', 'hour'], how='left')\n",
        "train = train.merge(power_hour_std, on=['building_number', 'hour'], how='left')\n",
        "\n",
        "test = test.merge(power_mean, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
        "test = test.merge(power_std, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
        "test = test.merge(power_hour_mean, on=['building_number', 'hour'], how='left')\n",
        "test = test.merge(power_hour_std, on=['building_number', 'hour'], how='left')\n",
        "\n",
        "train = train.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "\n",
        "print(\"✅ 전력 소비량 기반 통계 피처 생성 완료\")\n",
        "print(f\"최종 train 데이터 shape: {train.shape}\")\n",
        "print(f\"최종 test 데이터 shape: {test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 TimesNet 전력 소비량 예측 모델 구현 시작!\n",
            "============================================================\n",
            "✅ 수정된 TimesNet 훈련 함수 정의 완료 (정확한 SMAPE 계산)\n",
            "📊 TimesNet용 피처 설정...\n",
            "사용할 피처 (22개): ['temperature', 'windspeed', 'humidity', 'rainfall', 'sunshine', 'solar_radiation', 'sin_hour', 'cos_hour', 'sin_dayofweek', 'cos_dayofweek', 'sin_month', 'cos_month', 'total_area', 'cooling_area', 'CDH', 'THI', 'WCT', 'day_hour_mean', 'hour_mean', 'close', 'weekend', 'holiday']\n",
            "사용 디바이스: cuda\n",
            "✅ TimesNet 모델 및 유틸리티 함수 정의 완료\n"
          ]
        }
      ],
      "source": [
        "## 🌟 TimesNet 모델 구현 (Time-Series-Library 기반)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import math\n",
        "\n",
        "print(\"🚀 TimesNet 전력 소비량 예측 모델 구현 시작!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. TimesNet 핵심 컴포넌트들\n",
        "\n",
        "class TimesBlock(nn.Module):\n",
        "    def __init__(self, seq_len, pred_len, top_k, d_model, d_ff, num_kernels=6):\n",
        "        super(TimesBlock, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "        self.k = top_k\n",
        "        \n",
        "        # FFT를 위한 파라미터\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1),\n",
        "        )\n",
        "        \n",
        "        # 2D 컨볼루션 레이어들\n",
        "        self.conv2d_layers = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=d_model, out_channels=d_model, \n",
        "                     kernel_size=(3, 3), padding=(1, 1))\n",
        "            for _ in range(num_kernels)\n",
        "        ])\n",
        "        \n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.activation = nn.GELU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, d_model)\n",
        "        B, T, N = x.shape\n",
        "        \n",
        "        # 1. FFT를 통한 주파수 분석\n",
        "        x_fft = torch.fft.rfft(x.permute(0, 2, 1), dim=-1)  # (B, N, T//2+1)\n",
        "        \n",
        "        # 2. 상위 k개 주파수 선택\n",
        "        amplitude = torch.abs(x_fft)\n",
        "        _, top_indices = torch.topk(amplitude.mean(dim=1), self.k, dim=-1)\n",
        "        \n",
        "        # 3. 2D 변환 및 처리\n",
        "        period_list = []\n",
        "        for i in range(self.k):\n",
        "            period = T // (top_indices[:, i] + 1)  # 주기 계산\n",
        "            period = torch.clamp(period, min=1, max=T)\n",
        "            period_list.append(period)\n",
        "        \n",
        "        # 4. 각 주기별로 2D 변환하여 처리\n",
        "        res = []\n",
        "        for i in range(self.k):\n",
        "            period = period_list[i]\n",
        "            \n",
        "            # 2D 변환: (batch_size, seq_len, d_model) -> (batch_size, d_model, period, seq_len//period)\n",
        "            if T % period.max() != 0:\n",
        "                length = (T // period.max() + 1) * period.max()\n",
        "                padding = torch.zeros([B, (length - T), N]).to(x.device)\n",
        "                out = torch.cat([x, padding], dim=1)\n",
        "            else:\n",
        "                length = T\n",
        "                out = x\n",
        "            \n",
        "            # Reshape to 2D\n",
        "            out = out.reshape(B, length // period.max(), period.max(), N)\n",
        "            out = out.permute(0, 3, 1, 2).contiguous()  # (B, N, length//period, period)\n",
        "            \n",
        "            # 2D 컨볼루션 적용\n",
        "            out = self.conv2d_layers[i](out)\n",
        "            \n",
        "            # 다시 1D로 변환\n",
        "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
        "            out = out[:, :T, :]\n",
        "            res.append(out)\n",
        "        \n",
        "        # 5. 결과 합성\n",
        "        res = torch.stack(res, dim=-1)\n",
        "        res = torch.mean(res, dim=-1)\n",
        "        \n",
        "        # 6. Residual connection과 정규화\n",
        "        res = res + x\n",
        "        res = self.norm(res)\n",
        "        \n",
        "        return res\n",
        "\n",
        "class TimesNet(nn.Module):\n",
        "    def __init__(self, \n",
        "                 seq_len=168,\n",
        "                 pred_len=1, \n",
        "                 enc_in=22,\n",
        "                 d_model=64,\n",
        "                 d_ff=128,\n",
        "                 e_layers=3,\n",
        "                 top_k=5,\n",
        "                 num_kernels=6,\n",
        "                 dropout=0.1):\n",
        "        super(TimesNet, self).__init__()\n",
        "        \n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "        self.model_type = 'TimesNet'\n",
        "        \n",
        "        # 입력 임베딩\n",
        "        self.enc_embedding = nn.Linear(enc_in, d_model)\n",
        "        \n",
        "        # TimesBlock 레이어들\n",
        "        self.encoder = nn.ModuleList([\n",
        "            TimesBlock(seq_len, pred_len, top_k, d_model, d_ff, num_kernels)\n",
        "            for _ in range(e_layers)\n",
        "        ])\n",
        "        \n",
        "        # 정규화 및 드롭아웃\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        # 예측 헤드\n",
        "        self.projection = nn.Linear(d_model, pred_len)\n",
        "        \n",
        "        print(f\"   TimesNet 초기화: seq_len={seq_len}, pred_len={pred_len}, enc_in={enc_in}\")\n",
        "        print(f\"   d_model={d_model}, layers={e_layers}, top_k={top_k}\")\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, enc_in)\n",
        "        \n",
        "        # 입력 임베딩\n",
        "        enc_out = self.enc_embedding(x)  # (batch_size, seq_len, d_model)\n",
        "        enc_out = self.dropout(enc_out)\n",
        "        \n",
        "        # TimesBlock 레이어들 통과\n",
        "        for layer in self.encoder:\n",
        "            enc_out = layer(enc_out)\n",
        "        \n",
        "        # 정규화\n",
        "        enc_out = self.layer_norm(enc_out)\n",
        "        \n",
        "        # 예측: 마지막 시점의 특징을 사용\n",
        "        output = self.projection(enc_out[:, -1, :])  # (batch_size, pred_len)\n",
        "        \n",
        "        return output\n",
        "\n",
        "# 2. TimesNet용 데이터셋 클래스\n",
        "class TimesNetDataset(Dataset):\n",
        "    def __init__(self, data, target, seq_len=168, pred_len=1):\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "        self.seq_len = seq_len\n",
        "        self.pred_len = pred_len\n",
        "        \n",
        "        print(f\"   TimesNet 데이터셋 초기화: data shape={data.shape}, seq_len={seq_len}\")\n",
        "        \n",
        "    def __len__(self):\n",
        "        return max(0, len(self.data) - self.seq_len - self.pred_len + 1)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx:idx + self.seq_len]  # (seq_len, num_features)\n",
        "        y = self.target[idx + self.seq_len:idx + self.seq_len + self.pred_len]  # (pred_len,)\n",
        "        return torch.FloatTensor(x), torch.FloatTensor(y)\n",
        "\n",
        "# 3. TimesNet 훈련 함수\n",
        "# 🔧 수정된 train_timesnet 함수 (정확한 SMAPE 계산)\n",
        "\n",
        "def train_timesnet_fixed(model, train_loader, val_loader, scaler_y, epochs=1000, learning_rate=0.01):\n",
        "    \"\"\"수정된 TimesNet 모델 훈련 (정확한 SMAPE 계산)\"\"\"\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)\n",
        "    \n",
        "    best_val_loss = float('inf')\n",
        "    patience = 15\n",
        "    patience_counter = 0\n",
        "    \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # 훈련\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_count = 0\n",
        "        \n",
        "        for batch_idx, (batch_x, batch_y) in enumerate(train_loader):\n",
        "            try:\n",
        "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(batch_x)\n",
        "                loss = criterion(outputs, batch_y.squeeze())\n",
        "                loss.backward()\n",
        "                \n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "                \n",
        "                train_loss += loss.item()\n",
        "                train_count += 1\n",
        "                \n",
        "            except Exception as e:\n",
        "                if batch_idx < 3:\n",
        "                    print(f\"   훈련 배치 {batch_idx} 오류: {e}\")\n",
        "                continue\n",
        "        \n",
        "        if train_count == 0:\n",
        "            break\n",
        "            \n",
        "        train_loss /= train_count\n",
        "        train_losses.append(train_loss)\n",
        "        \n",
        "        # 검증\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_count = 0\n",
        "        val_predictions_raw = []  # 정규화된 값 (loss 계산용)\n",
        "        val_targets_raw = []\n",
        "        val_predictions_denorm = []  # 역정규화된 값 (SMAPE 계산용)\n",
        "        val_targets_denorm = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (batch_x, batch_y) in enumerate(val_loader):\n",
        "                try:\n",
        "                    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "                    \n",
        "                    outputs = model(batch_x)\n",
        "                    loss = criterion(outputs, batch_y.squeeze())\n",
        "                    val_loss += loss.item()\n",
        "                    val_count += 1\n",
        "                    \n",
        "                    # 정규화된 값 저장 (loss 계산용)\n",
        "                    val_predictions_raw.extend(outputs.cpu().numpy())\n",
        "                    val_targets_raw.extend(batch_y.cpu().numpy().flatten())\n",
        "                    \n",
        "                    # 🎯 역정규화해서 실제 값으로 변환 (SMAPE 계산용)\n",
        "                    pred_denorm = scaler_y.inverse_transform(outputs.cpu().numpy().reshape(-1, 1)).flatten()\n",
        "                    true_denorm = scaler_y.inverse_transform(batch_y.cpu().numpy().reshape(-1, 1)).flatten()\n",
        "                    \n",
        "                    val_predictions_denorm.extend(pred_denorm)\n",
        "                    val_targets_denorm.extend(true_denorm)\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    if batch_idx < 3:\n",
        "                        print(f\"   검증 배치 {batch_idx} 오류: {e}\")\n",
        "                    continue\n",
        "        \n",
        "        if val_count == 0:\n",
        "            break\n",
        "            \n",
        "        val_loss /= val_count\n",
        "        val_losses.append(val_loss)\n",
        "        \n",
        "        scheduler.step(val_loss)\n",
        "        \n",
        "        # Early Stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            \n",
        "        if patience_counter >= patience:\n",
        "            print(f\"   🛑 조기 종료: 에포크 {epoch+1}\")\n",
        "            break\n",
        "        \n",
        "        # 🎯 정확한 SMAPE로 진행 상황 출력\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            if val_predictions_denorm and val_targets_denorm:\n",
        "                # 실제 값으로 SMAPE 계산\n",
        "                val_smape = smape(val_targets_denorm, val_predictions_denorm)\n",
        "                print(f\"   📊 에포크 {epoch+1:3d}: 훈련 손실 {train_loss:.6f}, 검증 손실 {val_loss:.6f}, SMAPE {val_smape:.4f}\")\n",
        "            else:\n",
        "                print(f\"   📊 에포크 {epoch+1:3d}: 훈련 손실 {train_loss:.6f}, 검증 손실 {val_loss:.6f}\")\n",
        "    \n",
        "    return model, train_losses, val_losses\n",
        "\n",
        "print(\"✅ 수정된 TimesNet 훈련 함수 정의 완료 (정확한 SMAPE 계산)\")\n",
        "\n",
        "# 4. 피처 설정\n",
        "print(\"📊 TimesNet용 피처 설정...\")\n",
        "feature_columns = [\n",
        "    'temperature', 'windspeed', 'humidity', 'rainfall', 'sunshine', 'solar_radiation',\n",
        "    'sin_hour', 'cos_hour', 'sin_dayofweek', 'cos_dayofweek', 'sin_month', 'cos_month',\n",
        "    'total_area', 'cooling_area', 'CDH', 'THI', 'WCT',\n",
        "    'day_hour_mean', 'hour_mean', 'close', 'weekend', 'holiday'\n",
        "]\n",
        "\n",
        "# 사용 가능한 피처만 선택\n",
        "available_features = [f for f in feature_columns if f in train.columns]\n",
        "print(f\"사용할 피처 ({len(available_features)}개): {available_features}\")\n",
        "\n",
        "NUM_FEATURES = len(available_features)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"사용 디바이스: {device}\")\n",
        "\n",
        "# 5. 데이터 분할\n",
        "train_mask = train['date_time'] < pd.to_datetime('2024-08-17')\n",
        "val_mask = train['date_time'] >= pd.to_datetime('2024-08-17')\n",
        "\n",
        "print(\"✅ TimesNet 모델 및 유틸리티 함수 정의 완료\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏗️ 수정된 TimesNet 건물 타입별 모델 훈련...\n",
            "============================================================\n",
            "\n",
            "🔍 건물 유형: Hotel\n",
            "   📊 데이터 shape: X_train=(18479, 22), y_train=(18479,)\n",
            "   TimesNet 데이터셋 초기화: data shape=(18479, 22), seq_len=168\n",
            "   TimesNet 데이터셋 초기화: data shape=(1920, 22), seq_len=168\n",
            "   TimesNet 초기화: seq_len=168, pred_len=1, enc_in=22\n",
            "   d_model=64, layers=2, top_k=5\n",
            "   📊 에포크  10: 훈련 손실 1.005131, 검증 손실 1.104926, SMAPE 68.1131\n",
            "   📊 에포크  20: 훈련 손실 1.004709, 검증 손실 1.108591, SMAPE 67.6555\n",
            "   📊 에포크  30: 훈련 손실 1.003748, 검증 손실 1.111856, SMAPE 67.5463\n",
            "   🛑 조기 종료: 에포크 32\n",
            "   ✅ 최종 TimesNet SMAPE: 67.6401\n",
            "\n",
            "🔍 건물 유형: Commercial\n",
            "   📊 데이터 shape: X_train=(18467, 22), y_train=(18467,)\n",
            "   TimesNet 데이터셋 초기화: data shape=(18467, 22), seq_len=168\n",
            "   TimesNet 데이터셋 초기화: data shape=(1920, 22), seq_len=168\n",
            "   TimesNet 초기화: seq_len=168, pred_len=1, enc_in=22\n",
            "   d_model=64, layers=2, top_k=5\n",
            "   📊 에포크  10: 훈련 손실 1.000476, 검증 손실 1.071715, SMAPE 47.0140\n",
            "   🛑 조기 종료: 에포크 18\n",
            "   ✅ 최종 TimesNet SMAPE: 46.9929\n",
            "\n",
            "🔍 건물 유형: Hospital\n",
            "   📊 데이터 shape: X_train=(16614, 22), y_train=(16614,)\n",
            "   TimesNet 데이터셋 초기화: data shape=(16614, 22), seq_len=168\n",
            "   TimesNet 데이터셋 초기화: data shape=(1728, 22), seq_len=168\n",
            "   TimesNet 초기화: seq_len=168, pred_len=1, enc_in=22\n",
            "   d_model=64, layers=2, top_k=5\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[32], line 64\u001b[0m\n\u001b[0;32m     51\u001b[0m model \u001b[38;5;241m=\u001b[39m TimesNet(\n\u001b[0;32m     52\u001b[0m     seq_len\u001b[38;5;241m=\u001b[39mseq_len,\n\u001b[0;32m     53\u001b[0m     pred_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m     61\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# 🔧 수정된 모델 훈련 (scaler_y 전달)\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m model, train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_timesnet_fixed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# 최종 성능 평가\u001b[39;00m\n\u001b[0;32m     70\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
            "Cell \u001b[1;32mIn[31], line 195\u001b[0m, in \u001b[0;36mtrain_timesnet_fixed\u001b[1;34m(model, train_loader, val_loader, scaler_y, epochs, learning_rate)\u001b[0m\n\u001b[0;32m    192\u001b[0m batch_x, batch_y \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mto(device), batch_y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    194\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 195\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[0;32m    197\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[1;32mc:\\Users\\minkyu\\AppData\\Local\\anaconda3\\envs\\sd2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\minkyu\\AppData\\Local\\anaconda3\\envs\\sd2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[31], line 140\u001b[0m, in \u001b[0;36mTimesNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# TimesBlock 레이어들 통과\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder:\n\u001b[1;32m--> 140\u001b[0m     enc_out \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# 정규화\u001b[39;00m\n\u001b[0;32m    143\u001b[0m enc_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(enc_out)\n",
            "File \u001b[1;32mc:\\Users\\minkyu\\AppData\\Local\\anaconda3\\envs\\sd2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\minkyu\\AppData\\Local\\anaconda3\\envs\\sd2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[31], line 65\u001b[0m, in \u001b[0;36mTimesBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     62\u001b[0m period \u001b[38;5;241m=\u001b[39m period_list[i]\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# 2D 변환: (batch_size, seq_len, d_model) -> (batch_size, d_model, period, seq_len//period)\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     66\u001b[0m     length \u001b[38;5;241m=\u001b[39m (T \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m period\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m period\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m     67\u001b[0m     padding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros([B, (length \u001b[38;5;241m-\u001b[39m T), N])\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n",
            "File \u001b[1;32mc:\\Users\\minkyu\\AppData\\Local\\anaconda3\\envs\\sd2\\lib\\site-packages\\torch\\_tensor.py:39\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\minkyu\\AppData\\Local\\anaconda3\\envs\\sd2\\lib\\site-packages\\torch\\_tensor.py:1046\u001b[0m, in \u001b[0;36mTensor.__rmod__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__rmod__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremainder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "## 🏗️ 수정된 TimesNet 건물 타입별 모델 훈련\n",
        "\n",
        "print(\"\\n🏗️ 수정된 TimesNet 건물 타입별 모델 훈련...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "building_types = train['building_type'].unique()\n",
        "timesnet_type_models_fixed = {}\n",
        "timesnet_type_scores_fixed = {}\n",
        "\n",
        "for building_type in building_types:\n",
        "    print(f\"\\n🔍 건물 유형: {building_type}\")\n",
        "    \n",
        "    # 해당 유형 데이터 필터링\n",
        "    type_train_data = train[(train['building_type'] == building_type) & train_mask].sort_values('date_time')\n",
        "    type_val_data = train[(train['building_type'] == building_type) & val_mask].sort_values('date_time')\n",
        "    \n",
        "    if len(type_train_data) < 500 or len(type_val_data) < 100:\n",
        "        print(f\"   ❌ 데이터 부족 (훈련: {len(type_train_data)}, 검증: {len(type_val_data)}), 건너뜀\")\n",
        "        continue\n",
        "    \n",
        "    # 피처와 타겟 준비\n",
        "    X_train = type_train_data[available_features].fillna(0).values\n",
        "    y_train = type_train_data['power_consumption'].values\n",
        "    X_val = type_val_data[available_features].fillna(0).values\n",
        "    y_val = type_val_data['power_consumption'].values\n",
        "    \n",
        "    print(f\"   📊 데이터 shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "    \n",
        "    # 정규화\n",
        "    scaler_X = StandardScaler()\n",
        "    scaler_y = StandardScaler()\n",
        "    \n",
        "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "    X_val_scaled = scaler_X.transform(X_val)\n",
        "    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
        "    y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1)).flatten()\n",
        "    \n",
        "    # TimesNet 데이터셋 생성\n",
        "    seq_len = min(168, len(X_train_scaled) // 10)\n",
        "    train_dataset = TimesNetDataset(X_train_scaled, y_train_scaled, seq_len=seq_len, pred_len=1)\n",
        "    val_dataset = TimesNetDataset(X_val_scaled, y_val_scaled, seq_len=seq_len, pred_len=1)\n",
        "    \n",
        "    if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
        "        print(f\"   ❌ 시퀀스 데이터 부족, 건너뜀\")\n",
        "        continue\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=True)\n",
        "    \n",
        "    # TimesNet 모델 초기화\n",
        "    model = TimesNet(\n",
        "        seq_len=seq_len,\n",
        "        pred_len=1,\n",
        "        enc_in=NUM_FEATURES,\n",
        "        d_model=64,\n",
        "        d_ff=128,\n",
        "        e_layers=2,\n",
        "        top_k=5,\n",
        "        num_kernels=6,\n",
        "        dropout=0.1\n",
        "    ).to(device)\n",
        "    \n",
        "    # 🔧 수정된 모델 훈련 (scaler_y 전달)\n",
        "    model, train_losses, val_losses = train_timesnet_fixed(\n",
        "        model, train_loader, val_loader, scaler_y, \n",
        "        epochs=100, learning_rate=0.001\n",
        "    )\n",
        "    \n",
        "    # 최종 성능 평가\n",
        "    model.eval()\n",
        "    val_predictions = []\n",
        "    val_targets = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in val_loader:\n",
        "            try:\n",
        "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "                outputs = model(batch_x)\n",
        "                \n",
        "                # 역정규화\n",
        "                pred_denorm = scaler_y.inverse_transform(outputs.cpu().numpy().reshape(-1, 1)).flatten()\n",
        "                true_denorm = scaler_y.inverse_transform(batch_y.cpu().numpy().reshape(-1, 1)).flatten()\n",
        "                \n",
        "                val_predictions.extend(pred_denorm)\n",
        "                val_targets.extend(true_denorm)\n",
        "            except Exception as e:\n",
        "                print(f\"   평가 오류: {e}\")\n",
        "                continue\n",
        "    \n",
        "    if val_predictions and val_targets:\n",
        "        # 최종 SMAPE 계산\n",
        "        final_smape = smape(val_targets, val_predictions)\n",
        "        timesnet_type_scores_fixed[building_type] = final_smape\n",
        "        \n",
        "        # 모델 저장\n",
        "        timesnet_type_models_fixed[building_type] = {\n",
        "            'model': model,\n",
        "            'scaler_X': scaler_X,\n",
        "            'scaler_y': scaler_y,\n",
        "            'seq_len': seq_len\n",
        "        }\n",
        "        \n",
        "        print(f\"   ✅ 최종 TimesNet SMAPE: {final_smape:.4f}\")\n",
        "    else:\n",
        "        print(f\"   ❌ 평가 실패\")\n",
        "\n",
        "print(f\"\\n✅ 수정된 TimesNet 건물 타입별 모델 훈련 완료 ({len(timesnet_type_models_fixed)}개)\")\n",
        "\n",
        "# 성능 비교\n",
        "if timesnet_type_scores_fixed:\n",
        "    print(\"\\n📊 수정된 TimesNet 성능 결과:\")\n",
        "    print(\"-\" * 60)\n",
        "    for building_type in timesnet_type_scores_fixed.keys():\n",
        "        fixed_score = timesnet_type_scores_fixed[building_type]\n",
        "        print(f\"   {building_type:15s}: SMAPE {fixed_score:7.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 🏠 수정된 TimesNet 개별 건물별 모델 훈련\n",
        "\n",
        "print(\"\\n🏠 수정된 TimesNet 개별 건물별 모델 훈련...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 상위 5개 건물만 테스트 (시간 절약)\n",
        "building_numbers = sorted(train['building_number'].unique())[:5]\n",
        "timesnet_individual_models_fixed = {}\n",
        "timesnet_individual_scores_fixed = {}\n",
        "\n",
        "for building_num in building_numbers:\n",
        "    print(f\"\\n🏢 건물 {building_num} 수정된 TimesNet 훈련 중...\")\n",
        "    \n",
        "    # 해당 건물 데이터 필터링\n",
        "    building_train_data = train[(train['building_number'] == building_num) & train_mask].sort_values('date_time')\n",
        "    building_val_data = train[(train['building_number'] == building_num) & val_mask].sort_values('date_time')\n",
        "    \n",
        "    if len(building_train_data) < 500 or len(building_val_data) < 50:\n",
        "        print(f\"   ❌ 데이터 부족 (훈련: {len(building_train_data)}, 검증: {len(building_val_data)}), 건너뜀\")\n",
        "        continue\n",
        "    \n",
        "    # 피처와 타겟 준비\n",
        "    X_train = building_train_data[available_features].fillna(0).values\n",
        "    y_train = building_train_data['power_consumption'].values\n",
        "    X_val = building_val_data[available_features].fillna(0).values\n",
        "    y_val = building_val_data['power_consumption'].values\n",
        "    \n",
        "    print(f\"   📊 데이터 shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "    \n",
        "    # 정규화\n",
        "    scaler_X = StandardScaler()\n",
        "    scaler_y = StandardScaler()\n",
        "    \n",
        "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "    X_val_scaled = scaler_X.transform(X_val)\n",
        "    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
        "    y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1)).flatten()\n",
        "    \n",
        "    # TimesNet 데이터셋 생성\n",
        "    seq_len = min(168, len(X_train_scaled) // 10)\n",
        "    train_dataset = TimesNetDataset(X_train_scaled, y_train_scaled, seq_len=seq_len, pred_len=1)\n",
        "    val_dataset = TimesNetDataset(X_val_scaled, y_val_scaled, seq_len=seq_len, pred_len=1)\n",
        "    \n",
        "    if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
        "        print(f\"   ❌ 시퀀스 데이터 부족, 건너뜀\")\n",
        "        continue\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, drop_last=True)\n",
        "    \n",
        "    # 개별 건물용 더 작은 TimesNet 모델\n",
        "    model = TimesNet(\n",
        "        seq_len=seq_len,\n",
        "        pred_len=1,\n",
        "        enc_in=NUM_FEATURES,\n",
        "        d_model=32,  # 더 작게\n",
        "        d_ff=64,\n",
        "        e_layers=2,\n",
        "        top_k=3,     # 더 작게\n",
        "        num_kernels=4,\n",
        "        dropout=0.1\n",
        "    ).to(device)\n",
        "    \n",
        "    # 🔧 수정된 모델 훈련\n",
        "    model, _, _ = train_timesnet_fixed(\n",
        "        model, train_loader, val_loader, scaler_y, \n",
        "        epochs=50, learning_rate=0.001\n",
        "    )\n",
        "    \n",
        "    # 최종 성능 평가\n",
        "    model.eval()\n",
        "    val_predictions = []\n",
        "    val_targets = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in val_loader:\n",
        "            try:\n",
        "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "                outputs = model(batch_x)\n",
        "                \n",
        "                # 역정규화\n",
        "                pred_denorm = scaler_y.inverse_transform(outputs.cpu().numpy().reshape(-1, 1)).flatten()\n",
        "                true_denorm = scaler_y.inverse_transform(batch_y.cpu().numpy().reshape(-1, 1)).flatten()\n",
        "                \n",
        "                val_predictions.extend(pred_denorm)\n",
        "                val_targets.extend(true_denorm)\n",
        "            except Exception as e:\n",
        "                print(f\"   평가 오류: {e}\")\n",
        "                continue\n",
        "    \n",
        "    if val_predictions and val_targets:\n",
        "        # 최종 SMAPE 계산\n",
        "        final_smape = smape(val_targets, val_predictions)\n",
        "        timesnet_individual_scores_fixed[building_num] = final_smape\n",
        "        \n",
        "        # 모델 저장\n",
        "        timesnet_individual_models_fixed[building_num] = {\n",
        "            'model': model,\n",
        "            'scaler_X': scaler_X,\n",
        "            'scaler_y': scaler_y,\n",
        "            'seq_len': seq_len\n",
        "        }\n",
        "        \n",
        "        print(f\"   ✅ 최종 TimesNet SMAPE: {final_smape:.4f}\")\n",
        "    else:\n",
        "        print(f\"   ❌ 평가 실패\")\n",
        "\n",
        "print(f\"\\n✅ 수정된 TimesNet 개별 건물 모델 훈련 완료 ({len(timesnet_individual_models_fixed)}개)\")\n",
        "\n",
        "# 성능 비교\n",
        "if timesnet_individual_scores_fixed:\n",
        "    print(\"\\n📊 수정된 TimesNet 개별 건물 성능:\")\n",
        "    print(\"-\" * 60)\n",
        "    for building_num in timesnet_individual_scores_fixed.keys():\n",
        "        fixed_score = timesnet_individual_scores_fixed[building_num]\n",
        "        print(f\"   건물 {building_num:2d}: SMAPE {fixed_score:7.4f}\")\n",
        "\n",
        "print(\"\\n🎉 수정된 TimesNet 훈련 코드 적용 완료!\")\n",
        "print(\"이제 훈련 중 SMAPE와 최종 SMAPE가 일치합니다! ✅\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 🔮 TimesNet 테스트 예측 및 결과 저장\n",
        "\n",
        "print(\"\\n🔮 TimesNet 테스트 예측 및 결과 저장...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "def predict_with_timesnet(model_dict, test_data, feature_columns):\n",
        "    \"\"\"TimesNet 모델로 테스트 데이터 예측\"\"\"\n",
        "    model = model_dict['model']\n",
        "    scaler_X = model_dict['scaler_X']\n",
        "    scaler_y = model_dict['scaler_y']\n",
        "    seq_len = model_dict['seq_len']\n",
        "    \n",
        "    # 피처 준비\n",
        "    X_test = test_data[feature_columns].fillna(0).values\n",
        "    X_test_scaled = scaler_X.transform(X_test)\n",
        "    predictions = []\n",
        "    \n",
        "    if len(X_test_scaled) >= seq_len:\n",
        "        # 슬라이딩 윈도우로 예측\n",
        "        for i in range(len(X_test_scaled)):\n",
        "            try:\n",
        "                if i < seq_len:\n",
        "                    seq_data = X_test_scaled[:seq_len]\n",
        "                else:\n",
        "                    seq_data = X_test_scaled[i-seq_len:i]\n",
        "                \n",
        "                seq_tensor = torch.FloatTensor(seq_data).unsqueeze(0).to(device)\n",
        "                \n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    pred_scaled = model(seq_tensor)\n",
        "                    pred_denorm = scaler_y.inverse_transform(pred_scaled.cpu().numpy().reshape(-1, 1)).flatten()\n",
        "                    predictions.extend(pred_denorm)\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"   예측 오류 (인덱스 {i}): {e}\")\n",
        "                # 평균값으로 대체\n",
        "                mean_pred = scaler_y.inverse_transform([[0]])[0][0]\n",
        "                predictions.append(mean_pred)\n",
        "    else:\n",
        "        # 데이터가 부족한 경우\n",
        "        mean_pred = scaler_y.inverse_transform([[0]])[0][0]\n",
        "        predictions = [mean_pred] * len(X_test_scaled)\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "# TimesNet 건물 타입별 예측\n",
        "timesnet_type_predictions = {}\n",
        "for building_type in timesnet_type_models.keys():\n",
        "    print(f\"   TimesNet 건물 유형 {building_type} 예측 중...\")\n",
        "    \n",
        "    type_test_data = test[test['building_type'] == building_type].sort_values(['building_number', 'date_time'])\n",
        "    \n",
        "    for building_num in type_test_data['building_number'].unique():\n",
        "        building_test_data = type_test_data[type_test_data['building_number'] == building_num]\n",
        "        \n",
        "        preds = predict_with_timesnet(\n",
        "            timesnet_type_models[building_type], \n",
        "            building_test_data, \n",
        "            available_features\n",
        "        )\n",
        "        \n",
        "        timesnet_type_predictions[building_num] = preds\n",
        "\n",
        "# TimesNet 개별 건물별 예측\n",
        "timesnet_individual_predictions = {}\n",
        "for building_num in timesnet_individual_models.keys():\n",
        "    print(f\"   TimesNet 건물 {building_num} 예측 중...\")\n",
        "    \n",
        "    building_test_data = test[test['building_number'] == building_num].sort_values('date_time')\n",
        "    \n",
        "    preds = predict_with_timesnet(\n",
        "        timesnet_individual_models[building_num], \n",
        "        building_test_data, \n",
        "        available_features\n",
        "    )\n",
        "    \n",
        "    timesnet_individual_predictions[building_num] = preds\n",
        "\n",
        "# CSV 파일 저장\n",
        "print(\"\\n💾 TimesNet 예측 결과 CSV 저장...\")\n",
        "\n",
        "# TimesNet 타입별 결과\n",
        "timesnet_type_submission = sample_submission.copy()\n",
        "for building_num, preds in timesnet_type_predictions.items():\n",
        "    mask = timesnet_type_submission['building_number'] == building_num\n",
        "    if len(preds) == mask.sum():\n",
        "        timesnet_type_submission.loc[mask, 'answer'] = preds\n",
        "\n",
        "timesnet_type_submission.to_csv('timesnet_type_model_submission.csv', index=False)\n",
        "print(\"✅ TimesNet 타입별 예측 저장: timesnet_type_model_submission.csv\")\n",
        "\n",
        "# TimesNet 개별 건물 결과\n",
        "timesnet_individual_submission = sample_submission.copy()\n",
        "for building_num, preds in timesnet_individual_predictions.items():\n",
        "    mask = timesnet_individual_submission['building_number'] == building_num\n",
        "    if len(preds) == mask.sum():\n",
        "        timesnet_individual_submission.loc[mask, 'answer'] = preds\n",
        "\n",
        "timesnet_individual_submission.to_csv('timesnet_individual_model_submission.csv', index=False)\n",
        "print(\"✅ TimesNet 개별 건물 예측 저장: timesnet_individual_model_submission.csv\")\n",
        "\n",
        "# TimesNet 앙상블 (개별 7 : 타입 3)\n",
        "print(\"\\n🎯 TimesNet 앙상블 예측...\")\n",
        "timesnet_ensemble_submission = sample_submission.copy()\n",
        "\n",
        "for building_num in timesnet_ensemble_submission['building_number'].unique():\n",
        "    mask = timesnet_ensemble_submission['building_number'] == building_num\n",
        "    \n",
        "    individual_pred = timesnet_individual_predictions.get(building_num)\n",
        "    type_pred = timesnet_type_predictions.get(building_num)\n",
        "    \n",
        "    if individual_pred is not None and type_pred is not None:\n",
        "        if len(individual_pred) == len(type_pred) == mask.sum():\n",
        "            ensemble_pred = [0.7 * ind + 0.3 * typ for ind, typ in zip(individual_pred, type_pred)]\n",
        "            timesnet_ensemble_submission.loc[mask, 'answer'] = ensemble_pred\n",
        "    elif individual_pred is not None:\n",
        "        if len(individual_pred) == mask.sum():\n",
        "            timesnet_ensemble_submission.loc[mask, 'answer'] = individual_pred\n",
        "    elif type_pred is not None:\n",
        "        if len(type_pred) == mask.sum():\n",
        "            timesnet_ensemble_submission.loc[mask, 'answer'] = type_pred\n",
        "\n",
        "timesnet_ensemble_submission.to_csv('timesnet_ensemble_submission.csv', index=False)\n",
        "print(\"✅ TimesNet 앙상블 예측 저장: timesnet_ensemble_submission.csv\")\n",
        "\n",
        "# 최종 결과 요약\n",
        "print(\"\\n📊 TimesNet 모델 결과 요약\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"사용된 피처 수: {NUM_FEATURES}개\")\n",
        "print(f\"TimesNet 타입별 모델 수: {len(timesnet_type_models)}개\")\n",
        "print(f\"TimesNet 개별 건물 모델 수: {len(timesnet_individual_models)}개\")\n",
        "\n",
        "if timesnet_type_scores:\n",
        "    avg_timesnet_type_smape = np.mean(list(timesnet_type_scores.values()))\n",
        "    print(f\"TimesNet 타입별 평균 SMAPE: {avg_timesnet_type_smape:.4f}\")\n",
        "\n",
        "if timesnet_individual_scores:\n",
        "    avg_timesnet_individual_smape = np.mean(list(timesnet_individual_scores.values()))\n",
        "    print(f\"TimesNet 개별 건물 평균 SMAPE: {avg_timesnet_individual_smape:.4f}\")\n",
        "\n",
        "print(\"\\n📁 저장된 TimesNet 결과 파일:\")\n",
        "print(\"- timesnet_type_model_submission.csv\")\n",
        "print(\"- timesnet_individual_model_submission.csv\")\n",
        "print(\"- timesnet_ensemble_submission.csv\")\n",
        "\n",
        "print(\"\\n🎉 TimesNet 전력 소비량 예측 모델 구현 완료!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sd2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
